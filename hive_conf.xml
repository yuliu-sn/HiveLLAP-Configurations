<!--This XML file does not appear to have any style information associated with it. The document tree is shown below.
-->
<configuration>
<property>
<name>mapreduce.jobhistory.jhist.format</name>
<value>binary</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.retry.interval</name>
<value>500ms</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.proxyuser.hive.groups</name>
<value>*</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.block.access.token.lifetime</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.application.framework.path</name>
<value>
/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.skewjoin.key</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.heap.memory-mb.ratio</name>
<value>0.8</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.map.log.level</name>
<value>INFO</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.namenode.lazypersist.file.scrub.interval.sec</name>
<value>300</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.admin.user.env</name>
<value>
LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.llap.daemon.shuffle.dir.watcher.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>file.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.internal.ss.authz.settings.applied.marker</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>mapreduce.client.completion.pollinterval</name>
<value>5000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.azure.secure.mode</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.log-aggregation-enable</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.llap.daemon.num.file.cleaner.threads</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.aux-services.mapreduce_shuffle.class
</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.edit.log.autoroll.check.interval.ms</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.retry-after-speculate</name>
<value>15000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ipc.client.fallback-to-simple-auth-allowed</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.failover.connection.retries</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.event.db.listener.timetolive</name>
<value>86400s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.scheduler.minimum-allocation-mb</name>
<value>1024</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.task.profile.map.params</name>
<value>${mapreduce.task.profile.params}</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.llap.zk.sm.session.timeout</name>
<value>40s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.qjm.operations.timeout</name>
<value>60s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.memory.mb</name>
<value>5120</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.spark.explain.user</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.transfer.socket.recv.buffer.size</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.log.server.url</name>
<value>
http://ip-10-0-11-101.ap-northeast-1.compute.internal:19888/jobhistory/logs
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.authentication</name>
<value>NONE</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.vectorized.groupby.complex.types.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.failed.volumes.tolerated</name>
<value>1</value>
<final>true</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>_hive.tmp_table_space</name>
<value>
/tmp/hive/hive/589fe63b-b5be-46bd-b009-b9844af3bcf3/_tmp_space.db
</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>dfs.namenode.metrics.logger.period.seconds</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>stream.stderr.reporter.prefix</name>
<value>reporter:</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.slow.io.warning.threshold.ms</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.reservation-system.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.groups.cache.secs</name>
<value>300</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.metastore.stats.ndv.tuner</name>
<value>0.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.webapp.xfs-filter.xframe-options
</name>
<value>SAMEORIGIN</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.env-whitelist</name>
<value>
JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.top.window.num.buckets</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.authorization.storage.checks</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.client.hedged.read.threshold.millis</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.tez.java.opts</name>
<value>
-server -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>map.sort.class</name>
<value>org.apache.hadoop.util.QuickSort</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.safemode.threshold-pct</name>
<value>1</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.tez.bucket.pruning</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.llap.task.communicator.connection.timeout.ms</name>
<value>16000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>datanucleus.storeManagerType</name>
<value>rdbms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.blobstore.use.blobstore.as.scratchdir</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
</name>
<value>0</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.s3a.impl</name>
<value>org.apache.hadoop.fs.s3a.S3A</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.distcp.privileged.doAs</name>
<value>hive</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.caller.context.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
hive.metastore.aggregate.stats.cache.max.writer.wait
</name>
<value>5000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.use.lrfu</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.provided.aliasmap.load.retries</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.client.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.balancer.moverThreads</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.registry.dns.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>mapreduce.job.end-notification.max.retry.interval</name>
<value>5000</value>
<final>true</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.authentication</name>
<value>simple</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.client.mmap.retry.timeout.ms</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.download.permanent.fns</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.readahead.bytes</name>
<value>4194304</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.resultset.default.fetch.size</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.max-age-ms</name>
<value>604800000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.external.table.purge.default</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.app.mapreduce.client-am.ipc.max-retries</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.mapjoin.followby.map.aggr.hash.percentmemory</name>
<value>0.3</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.script.recordwriter</name>
<value>org.apache.hadoop.hive.ql.exec.TextRecordWriter</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.multigroupby.singlereducer</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.sleep-delay-before-sigkill.ms</name>
<value>250</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.vectorized.execution.reduce.groupby.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.registry.dns.domain-name</name>
<value>EXAMPLE.COM</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.authentication.ldap.guidKey</name>
<value>uid</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.system-metrics-publisher.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hadoop.shell.missing.defaultFs.warning</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.trash.interval</name>
<value>120</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>fs.har.impl</name>
<value>org.apache.hadoop.hive.shims.HiveHarFileSystem</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.max.locked.memory</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.http.filter.initializers</name>
<value>
org.apache.hadoop.security.AuthenticationFilterInitializer,org.apache.hadoop.security.HttpCrossOriginFilterInitializer
</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.always-scan-user-dir</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.hook.proto.queue.capacity</name>
<value>64</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.ipc.address</name>
<value>0.0.0.0:8010</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.llap.file.cleanup.delay.seconds</name>
<value>300s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.delegation.token.renew-interval</name>
<value>86400000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
dfs.datanode.ec.reconstruction.stripedread.timeout.millis
</name>
<value>5000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8088
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.spark.client.rpc.sasl.mechanisms</name>
<value>DIGEST-MD5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.web.authentication.filter</name>
<value>org.apache.hadoop.hdfs.web.AuthFilter</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.numa-awareness.numactl.cmd</name>
<value>/usr/bin/numactl</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.max.connections</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.local-cache.max-files-per-directory
</name>
<value>8192</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.log-aggregation.num-log-files-per-app
</name>
<value>30</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.query.reexecution.stats.cache.batch.size</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.namenode.replication.work.multiplier.per.iteration
</name>
<value>2</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.test.drop.namenode.response.number</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.ftp.impl</name>
<value>org.apache.hadoop.fs.ftp.FTPFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.optimize.remove.sq_count_check</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.slow.io.warning.threshold.ms</name>
<value>300</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.client.max-cached-nodemanagers-proxies</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.web.ssl</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.server-defaults.validity.period.ms</name>
<value>3600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.stats.filter.in.min.ratio</name>
<value>0.05</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.registry.zk.quorum</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:2181,ip-10-0-11-120.ap-northeast-1.compute.internal:2181,ip-10-0-11-12.ap-northeast-1.compute.internal:2181
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.job.committer.commit-window</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.session.timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.tez.exec.print.summary</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.heartbeat.recheck-interval</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
mapreduce.job.encrypted-intermediate-data-key-size-bits
</name>
<value>128</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>nfs.exports.allowed.hosts</name>
<value>* rw</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
hive.test.vectorization.suppress.explain.execution.mode
</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.filter.hook</name>
<value>
org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>hive.llap.io.orc.time.counters</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.write.byte-array-manager.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.retry.policy.spec</name>
<value>10000,6,60000,10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.integral.jdo.pushdown</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.util.hash.type</name>
<value>murmur</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.committer.name</name>
<value>file</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>llap.shuffle.connection-keep-alive.timeout</name>
<value>60</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.replication.min</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.webui.use.ssl</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.admin.map.child.java.opts</name>
<value>
-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.tez.bigtable.minsize.semijoin.reduction</name>
<value>100000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.task.scheduler.am.registry</name>
<value>llap</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.cli.print.current.db</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.debug.localtask</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.app-collector.linger-period.ms
</name>
<value>60000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.security.authorization.enabled</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hiveserver2-site.xml</source>
</property>
<property>
<name>hadoop.security.key.default.cipher</name>
<value>AES/CTR/NoPadding</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.hbase.configuration.file</name>
<value>
file:///usr/hdp/3.0.1.0-187/hadoop/conf/embedded-yarn-ats-hbase/hbase-site.xml
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.net.topology.impl</name>
<value>org.apache.hadoop.hdfs.net.DFSNetworkTopology</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.stats.fetch.bitvector</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.allocator.mmap.path</name>
<value>/tmp</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.output.stream.timeout</name>
<value>120s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.vectorized.use.row.serde.deserialize</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.llap.task.scheduler.node.reenable.min.timeout.ms
</name>
<value>200ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8030
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.metastore.try.direct.sql</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.spark.dynamic.partition.pruning.max.data.size</name>
<value>104857600</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.search.filter.user
</name>
<value>(&(objectClass=user)(sAMAccountName={0}))</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.lock.detailed-metrics.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.permissions.superusergroup</name>
<value>hdfs</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.resource-tracker.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8025
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.fileoutputcommitter.task.cleanup.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.http.client.retry.max.attempts</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.execution.engine</name>
<value>tez</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.notification.sequence.lock.max.retries</name>
<value>5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.node-ip-cache.expiry-interval-secs
</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.domain.socket.disable.interval.seconds</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-container-queuing.load-comparator
</name>
<value>QUEUE_LENGTH</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.io.vrb.queue.limit.base</name>
<value>50000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.root-dir</name>
<value>/sharedcache</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.enable.grace.join.in.llap</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.xframe.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>credentialStoreClassPath</name>
<value>/var/lib/ambari-agent/cred/lib/*</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.script.operator.env.blacklist</name>
<value>
hive.txn.valid.txns,hive.txn.tables.valid.writeids,hive.txn.valid.writeids,hive.script.operator.env.blacklist
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.long.polling.timeout</name>
<value>5000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.node-labels.fs-store.retry-policy-spec</name>
<value>2000, 500</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
dfs.client.write.byte-array-manager.count-threshold
</name>
<value>128</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.bind-host</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.vectorized.testing.reducer.batch.size</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ambari.hive.db.schema.name</name>
<value>hive</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.orc.splits.include.file.footer</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.mapjoin.optimized.hashtable.probe.percent</name>
<value>0.5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.http-address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:50070
</value>
<final>true</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.pcores-vcores-multiplier</name>
<value>1.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.query.timeout.seconds</name>
<value>0s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
</name>
<value>3600</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.service.handler.count</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.auto.enforce.stats</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.webapp.rest-csrf.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.default-container-executor.log-dirs.permissions
</name>
<value>710</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.async.exec.wait.queue.size</name>
<value>100</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.use.dfs.network.topology</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.client.output.filter</name>
<value>FAILED</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.memory.limit.percent</name>
<value>0.25</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-container-queuing.min-queue-length
</name>
<value>5</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.aggregate.stats.cache.max.full</name>
<value>0.9</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>nfs.rtmax</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.default.fileformat</name>
<value>TextFile</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.vectorized.execution.reducesink.new.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.ssl.client.conf</name>
<value>ssl-client.xml</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.ftp.host</name>
<value>0.0.0.0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.http.compression.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.groupby</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.http.authentication.simple.anonymous.allowed
</name>
<value>true</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>nfs.server.port</name>
<value>2049</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.write-lock-reporting-threshold-ms</name>
<value>5000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.optimize.remove.identity.project</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.ha.tail-edits.namenode-retries</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.admin-command-opts</name>
<value>-Dhdp.version=${hdp.version}</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.strict.managed.tables</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.msck.repair.batch.size</name>
<value>3000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.ha.log-roll.period</name>
<value>120s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hadoop.security.kms.client.authentication.retry-count
</name>
<value>1</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.optimize.filter.stats.reduction</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.task.io.sort.factor</name>
<value>100</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.testing.remove.logs</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.https.address</name>
<value>0.0.0.0:50475</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.sharedcache.uploader.server.address</name>
<value>0.0.0.0:8046</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.unlock.numretries</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.job.debug.capture.stacktraces</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.hmshandler.retry.interval</name>
<value>2000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.clear.dangling.scratchdir.interval</name>
<value>1800s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.client.cache.initial.capacity</name>
<value>50</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.reduces</name>
<value>-1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.server2.webui.cors.allowed.origins</name>
<value>*</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.recovery.compaction-interval-secs</name>
<value>3600</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.optimize.countdistinct</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.stats.ndv.algo</name>
<value>hll</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.checkpoint.edits.dir</name>
<value>${dfs.namenode.checkpoint.dir}</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.cleaner.interval-ms</name>
<value>86400000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.admin.reduce.child.java.opts</name>
<value>
-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs
</name>
<value>3600</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.mm.allow.originals</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.content-summary.sleep-microsec</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.vmem-check-enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.blobstore.supported.schemes</name>
<value>s3,s3a,s3n</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
</name>
<value>^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.cli.print.header</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.task.local-fs.write-limit.bytes</name>
<value>-1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ha.health-monitor.sleep-after-disconnect.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.txn.heartbeat.threadpool.size</name>
<value>5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.file.close.num-committed-allowed</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.counters.max</name>
<value>130</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.metastore.use.SSL</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.running.reduce.limit</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.webapp.rest-csrf.methods-to-ignore
</name>
<value>GET,OPTIONS,HEAD</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.exec.default.partition.name</name>
<value>__HIVE_DEFAULT_PARTITION__</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.placement-constraints.algorithm.class
</name>
<value>
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.mapred.partitioner</name>
<value>
org.apache.hadoop.hive.ql.io.DefaultHivePartitioner
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.http.read.timeout</name>
<value>PT10M</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.datanode.du.reserved.pct</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.groupby.mapaggr.checkinterval</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.compile.lock.timeout</name>
<value>0s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.validate.acls</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.classloader</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.application.classpath</name>
<value>
$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*:/usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.connect.max-wait.ms</name>
<value>900000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.ha.automatic-failover.embedded
</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
dfs.client.block.write.locateFollowingBlock.initial.delay.ms
</name>
<value>400</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.map.aggr.hash.min.reduction</name>
<value>0.99</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.http-authentication.proxyuser.root.hosts
</name>
<value>ip-10-0-11-10.ap-northeast-1.compute.internal</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.authentication.spnego.keytab</name>
<value>HTTP/_HOST@EXAMPLE.COM</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.joblist.cache.size</name>
<value>20000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.qjournal.write-txns.timeout.ms</name>
<value>20000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile.maps</name>
<value>0-2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
dfs.client.short.circuit.replica.stale.threshold.ms
</name>
<value>1800000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.mode.local.auto.input.files.max</name>
<value>4</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.reencrypt.batch.size</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.compactor.worker.timeout</name>
<value>86400</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.llap.io.nonvector.wrapper.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
</name>
<value>2</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.maintenance.replication.min</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.variable.substitute</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.ssl.server.conf</name>
<value>ssl-server.xml</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>io.erasurecode.codec.rs-legacy.rawcoders</name>
<value>rs-legacy_java</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.state-store-class</name>
<value>
org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.test.mode.prefix</name>
<value>test_</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.s3guard.ddb.max.retries</name>
<value>9</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.in.repl.test</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.dml.events</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.generic-application-history.max-applications
</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.conf.internal.variable.list</name>
<value>
hive.added.files.path,hive.added.jars.path,hive.added.archives.path
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.txn.operational.properties</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.full.block.report.lease.length.ms</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.test.mode.samplefreq</name>
<value>32</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
mapreduce.input.fileinputformat.list-status.num-threads
</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.dir</name>
<value>${dfs.namenode.name.dir}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.orc.splits.include.fileid</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.authentication.spnego.principal</name>
<value>/etc/security/keytabs/spnego.service.keytab</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.qjournal.accept-recovery.timeout.ms</name>
<value>120000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hive.metastore.authorization.storage.check.externaltable.drop
</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.version</name>
<value>2.0f</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.permissions.umask-mode</name>
<value>022</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.proxy-user-privileges.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.socketcache.expiryMsec</name>
<value>3000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.vectorized.execution.reduce.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.skewjoin.mapjoin.map.tasks</name>
<value>10000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.zk-max-znode-size.bytes</name>
<value>1048576</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
hive.llap.memory.oversubscription.max.executors.per.query
</name>
<value>3</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.webapp.rest-csrf.custom-header
</name>
<value>X-XSRF-Header</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.service.hosts</name>
<value>@llap0</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.http.policy</name>
<value>HTTP_ONLY</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.client.write.max-packets-in-flight</name>
<value>80</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.path.based.cache.refresh.interval.ms</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.committer.staging.conflict-mode</name>
<value>fail</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.router.webapp.https.address</name>
<value>0.0.0.0:8091</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.cgroups.mount
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.qjournal.get-journal-state.timeout.ms</name>
<value>120000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>45</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.fuse.connection.timeout</name>
<value>300</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.adl.impl</name>
<value>org.apache.hadoop.fs.adl.Adl</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
hive.exec.orc.delta.streaming.optimizations.enabled
</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.committer.staging.unique-filenames</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.block.access.key.update.interval</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.token.tracking.ids.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ha.health-monitor.rpc-timeout.ms</name>
<value>45000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.azure.authorization.caching.enable</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.script.recordreader</name>
<value>org.apache.hadoop.hive.ql.exec.TextRecordReader</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.spark.use.op.stats</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.fail-fast</name>
<value>${yarn.fail-fast}</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.server.max.message.size</name>
<value>104857600</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.http.cross-origin.allowed-origins</name>
<value>regex:.*[.]compute[.]internal(:\d*)?</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.summary-store
</name>
<value>
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.resource-profiles.source-file</name>
<value>resource-profiles.json</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.async.exec.keepalive.time</name>
<value>10s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.log-aggregation-status.time-out.ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.task.preemption.metrics.intervals</name>
<value>30,60,300</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.client.submit.file.replication</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.groups.shell.command.timeout</name>
<value>0s</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.proxyuser.root.hosts</name>
<value>10.0.11.0/24</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.zookeeper.connection.max.retries</name>
<value>3</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.stats.list.num.entries</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.logging.operation.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.ssl.require.client.cert</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.tez.session.events.print.summary</name>
<value>none</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.cache.revocation.timeout.ms</name>
<value>900000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.login.timeout</name>
<value>20s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.ha.tail-edits.period</name>
<value>60s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.client.nodemanager-connect.retry-interval-ms</name>
<value>10000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.materializedview.rewriting.incremental</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.inotify.max.events.per.rpc</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.rpc.protection</name>
<value>authentication</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.fs.state-store.uri</name>
<value> </value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.zookeeper.connection.timeout</name>
<value>15s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.dynamic.partition</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.cbo.costmodel.hdfs.write</name>
<value>10.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.scan.period.hours</name>
<value>504</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.block.id.layout.upgrade.threads</name>
<value>12</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.tez.exec.inplace.progress</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.temporary.table.storage</name>
<value>default</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.read.shortcircuit.skip.checksum</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.cli.pretty.output.num.cols</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.counters.group.name</name>
<value>HIVE</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.client.retry.delay.seconds</name>
<value>1s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.vectorized.complex.types.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.sharedcache.store.in-memory.initial-delay-mins
</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.client.nodemanager-client-async.thread-pool-max-size
</name>
<value>500</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.transpose.aggr.join</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/lib/hadoop-hdfs/dn_socket</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.server2.active.passive.ha.recover.sessions</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.provided.storage.id</name>
<value>DS-PROVIDED</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.skip.proc-count.auto-incr</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.stale.datanode.interval</name>
<value>30000</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.cbo.costmodel.local.fs.write</name>
<value>4.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.join.cache.size</name>
<value>25000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.block.invalidate.limit</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.execution.mode</name>
<value>llap</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.tez.dynamic.semijoin.reduction</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.file.max.footer</name>
<value>100</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:10200
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.scheme.class</name>
<value>dfs</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>mapreduce.app-submission.cross-platform</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.archive.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.http.policy</name>
<value>HTTP_ONLY</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.metastore.archive.intermediate.original</name>
<value>_INTERMEDIATE_ORIGINAL</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.map.output.compress</name>
<value>false</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.server2.xsrf.filter.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.shuffle.max.threads</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
hive.cluster.delegation.token.store.zookeeper.znode
</name>
<value>/hive/cluster/delegation</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.done-dir</name>
<value>/mr-history/done</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.tez.auto.reducer.parallelism</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.security.authorization.manager</name>
<value>
org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.llap.daemon.communicator.num.threads</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.spark.client.connect.timeout</name>
<value>1000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.azure.user.agent.prefix</name>
<value>
User-Agent: APN/1.0 Hortonworks/1.0 HDP/3.0.1.0-187
</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.namenode.reject-unresolved-dn-topology-mapping</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.swebhdfs.impl</name>
<value>org.apache.hadoop.fs.SWebHdfs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.ssl.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.connection.establish.timeout</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.io.allocator.direct</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.stats.join.factor</name>
<value>1.1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.webui.use.pam</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.lock.suppress.warning.interval</name>
<value>10s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.queue.name</name>
<value>llap</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.reservation-system.planfollower.time-step
</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.enable</name>
<value>true</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.disk-validator</name>
<value>basic</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.node-labels.configuration-type</name>
<value>centralized</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.zookeeper.quorum</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:2181,ip-10-0-11-120.ap-northeast-1.compute.internal:2181,ip-10-0-11-12.ap-northeast-1.compute.internal:2181
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.exec.post.hooks</name>
<value>
org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
hive.cluster.delegation.token.store.zookeeper.connectString
</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:2181,ip-10-0-11-120.ap-northeast-1.compute.internal:2181,ip-10-0-11-12.ap-northeast-1.compute.internal:2181
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>datanucleus.cache.level2.type</name>
<value>none</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.job.reduce.slowstart.completedmaps</name>
<value>0.05</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.output.fileoutputformat.compress.type</name>
<value>BLOCK</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.tez.container.size</name>
<value>3072</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.parallelcopies</name>
<value>30</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.metastore.pre.event.listeners</name>
<value>
org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.delete.thread-count</name>
<value>4</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.edit.log.transfer.bandwidthPerSec</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.max-retries</name>
<value>30</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.opportunistic-container-allocation.enabled
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.ssl.enabled.protocols</name>
<value>TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.registry.dns.zone-mask</name>
<value>255.255.255.0</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.memory-mb</name>
<value>25600</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hadoop.kerberos.kinit.command</name>
<value>kinit</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.output.fileoutputformat.compress.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.kerberos.internal.spnego.principal</name>
<value>${dfs.web.authentication.kerberos.principal}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-localizer.log.level</name>
<value>INFO</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.uri.selection</name>
<value>RANDOM</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.monitor.capacity.preemption.intra-queue-preemption.enabled
</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.metastore.aggregate.stats.cache.fpp</name>
<value>0.01</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.convert.join.bucket.mapjoin.tez</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.block.access.token.protobuf.enable</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.sleep.interval.between.start.attempts</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.app.mapreduce.am.container.log.backups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.server2.webui.port</name>
<value>10502</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.task.profile</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.disk.balancer.max.disk.errors</name>
<value>5</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.io.use.fileid.path</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ipc.client.rpc-timeout.ms</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.running.map.limit</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.io.rcfile.record.interval</name>
<value>2147483647</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.ssl.hostname.verifier</name>
<value>DEFAULT</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.auto-update.containers</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.map.groupby.sorted</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.socket.read-timeout</name>
<value>60s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.output.service.port</name>
<value>15003</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>stream.stderr.reporter.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.connection.ssl.enabled</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds
</name>
<value>259200000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size
</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.client.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.compute.splits.in.am</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>io.seqfile.local.dir</name>
<value>${hadoop.tmp.dir}/io/local</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.directoryscan.threads</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.read.shortcircuit.buffer.size</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.counters.pull.interval</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.client.best-effort</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.cleaner.resource-sleep-ms</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.client.failover-retries</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.input.lineinputformat.linespermap</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.posix.attr.uid.name
</name>
<value>uidNumber</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.xprod.mapjoin.small.table.rows</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.tez.wm.am.registry.timeout</name>
<value>30s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.new.job.grouping.set.cardinality</name>
<value>30</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.indexer.memory.rownum.max</name>
<value>75000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-monitor.interval-ms</name>
<value>3000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.job.queuename</name>
<value>default</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-monitor.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>javax.jdo.option.NonTransactionalRead</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.replication.max-streams-hard-limit</name>
<value>4</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.dns.nameserver</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.balancer.address</name>
<value>0.0.0.0:0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.streaming.auto.flush.check.interval.size</name>
<value>100Mb</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.webapp.rest-csrf.custom-header</name>
<value>X-XSRF-Header</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.cli.errors.ignore</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory
</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
dfs.datanode.directoryscan.throttle.limit.ms.per.sec
</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore
</name>
<value>GET,OPTIONS,HEAD</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.exec.mode.local.auto.inputbytes.max</name>
<value>134217728</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.hbase-schema.prefix</name>
<value>prod.</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.optimize.semijoin.conversion</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.reencrypt.sleep.interval</name>
<value>1m</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.stageid.rearrange</name>
<value>none</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.configuration.file-system-based-store
</name>
<value>/yarn/conf</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.automatic.close</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.spark.use.groupby.shuffle</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.read.striped.threadpool.size</name>
<value>18</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.llap.io.encode.slice.row.count</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.qjournal.select-input-streams.timeout.ms</name>
<value>20000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.failover.sleep.max.millis</name>
<value>15000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.node-labels.provider.fetch-timeout-ms
</name>
<value>1200000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.max-completed-applications</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.retry.throttle.limit</name>
<value>${fs.s3a.attempts.maximum}</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.staging-dir</name>
<value>/user</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.vectorized.execution.mapjoin.minmax.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.server2.thrift.http.path</name>
<value>cliservice</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nm.liveness-monitor.expiry-interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.fetch.retry.enabled</name>
<value>1</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.datanode.disk.check.timeout</name>
<value>10m</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>datanucleus.autoCreateSchema</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.s3a.multiobjectdelete.enable</name>
<value>true</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.metastore.transactional.event.listeners</name>
<value>
org.apache.hive.hcatalog.listener.DbNotificationListener
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.optimize.metadataonly</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.exec.input.listing.max.threads</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.balancer.max-no-move-interval</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.mapred.reduce.tasks.speculative.execution</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.query.reexecution.stats.cache.size</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.task.factory</name>
<value>
org.apache.hive.hcatalog.api.repl.exim.EximReplicationTaskFactory
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.lockmgr.zookeeper.default.partition.name</name>
<value>__HIVE_DEFAULT_ZOOKEEPER_PARTITION__</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.conf.validation</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ftp.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.heapsize</name>
<value>1024</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.numa-awareness.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.kerberos.principal</name>
<value>hive/_HOST@EXAMPLE.COM</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.prewarm.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.task.io.sort.mb</name>
<value>2047</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.llap.daemon.memory.per.instance.mb</name>
<value>4096</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.kms.client.encrypted.key.cache.expiry
</name>
<value>43200000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
dfs.namenode.snapshot.skip.capture.accesstime-only-change
</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.fetch.task.conversion</name>
<value>more</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.router.clientrm.interceptor-class.pipeline</name>
<value>
org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.server.min.threads</name>
<value>200</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.llap.concurrent.queries</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.dumpdir.clean.freq</name>
<value>0s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.address</name>
<value>0.0.0.0:8049</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ftp.blocksize</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.registry.jaas.context</name>
<value>Client</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.tez.min.bloom.filter.entries</name>
<value>1000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.container.stderr.pattern</name>
<value>{*stderr*,*STDERR*}</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-dirs</name>
<value>/hadoop/yarn/log,/mnt/datavol/hadoop/yarn/log</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.security.metastore.authorization.manager</name>
<value>
org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.metastore.server.tcp.keepalive</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.vectorized.groupby.checkinterval</name>
<value>4096</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.datanode.disk.check.min.gap</name>
<value>15m</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.operation.log.cleanup.delay</name>
<value>300s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.task.scheduler.enable.preemption</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.df.interval</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.blockreport.incremental.intervalMsec</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>io.skip.checksum.errors</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.jetty.logs.serve.aliases</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.exec.dynamic.partition.mode</name>
<value>nonstrict</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.orc.splits.allow.synthetic.fileid</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.bucketingsorting</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.remote-app-log-dir-suffix</name>
<value>logs</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.merge.mapredfiles</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.max.op.size</name>
<value>52428800</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.context</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.parallel</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.log.explain.output</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.edits.noeditlogchannelflush</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource.memory.cgroups.swappiness
</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
dfs.namenode.reencrypt.throttle.limit.handler.ratio
</name>
<value>1.0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>io.serializations</name>
<value>
org.apache.hadoop.io.serializer.WritableSerialization
</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.custom-header</name>
<value>X-XSRF-HEADER</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.skip.maxgroups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
mapreduce.jobhistory.webapp.rest-csrf.custom-header
</name>
<value>X-XSRF-Header</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.ha.fencing.ssh.connect-timeout</name>
<value>30000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.tez.cpu.vcores</name>
<value>-1</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.query.reexecution.stats.persist.scope</name>
<value>query</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.execution.mode</name>
<value>auto</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.journalnode.sync.interval</name>
<value>120000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.client.thread-count</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.proxyuser.hdfs.hosts</name>
<value>*</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.in.ssl.test</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.namenode.missing.checkpoint.periods.before.shutdown
</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.mapjoin.testing.no.hash.table.load</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.random.device.file.path</name>
<value>/dev/urandom</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.cbo.costmodel.extended</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.max.total.tasks</name>
<value>10</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.binary.record.max.length</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>datanucleus.schema.validateTables</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.multi.insert.move.tasks.share.dependencies</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.fast.upload.buffer</name>
<value>disk</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>net.topology.script.file.name</name>
<value>/etc/hadoop/conf/topology_script.py</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.posix.attr.gid.name
</name>
<value>gidNumber</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.windows-container.memory-limit.enabled
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.node-labels.resync-interval-ms</name>
<value>120000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
mapreduce.job.speculative.speculative-cap-total-tasks
</name>
<value>0.01</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.client.retry.times.get-last-block-length</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.federation.cache-ttl.secs</name>
<value>300</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.test.vectorized.adaptor.override</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.compactor.abortedtxn.threshold</name>
<value>1000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.audit.log.token.tracking.id</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.bp-ready.timeout</name>
<value>20s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.journalnode.https-address</name>
<value>0.0.0.0:8481</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>dfs.namenode.enable.retrycache</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.snapshot.max.limit</name>
<value>65536</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hive.auto.convert.sortmerge.join.bigtable.selection.policy
</name>
<value>
org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.audit.log.async</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-state-store.path</name>
<value>/hadoop/yarn/timeline</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.udtf.auto.progress</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.journalnode.rpc-address</name>
<value>0.0.0.0:8485</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.fileio.profiling.sampling.percentage</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.load.data.owner</name>
<value>hive</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.stats.fetch.column.stats</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.http.client.failover.sleep.base.millis</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.app-checker.class</name>
<value>
org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.num.executors</name>
<value>3</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.exec.reducers.bytes.per.reducer</name>
<value>67108864</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.reorder.nway.joins</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.socket.write.timeout</name>
<value>480000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.hook.proto.base-directory</name>
<value>
/warehouse/tablespace/external/hive/sys.db/query_data/
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.container.log.limit.kb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.placement-constraints.retry-attempts
</name>
<value>3</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.group</name>
<value>hadoop</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.io.rcfile.tolerate.corruptions</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.crypto.cipher.suite</name>
<value>AES/CTR/NoPadding</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
hadoop.security.kms.client.failover.sleep.base.millis
</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.placement-constraints.algorithm.pool-size
</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.msck.path.validation</name>
<value>throw</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.test.rollbacktxn</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.fs.state-store.retry-policy-spec
</name>
<value>2000, 500</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.disk.balancer.plan.valid.interval</name>
<value>1d</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.hard-kill-timeout-ms</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.key.bitlength</name>
<value>128</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.hs2.coordinator.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.ipc.rpc.class</name>
<value>org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.compat</name>
<value>0.12</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>file.replication</name>
<value>1</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.tez.bmj.use.subcache</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.drop.cache.behind.writes</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.data.transfer.server.tcpnodelay</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.zk.timeout-ms</name>
<value>10000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs
</name>
<value>20</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.balancer.max-size-to-move</name>
<value>10737418240</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.sharedcache.mode</name>
<value>disabled</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>15</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>rpc.metrics.quantile.enable</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled
</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.hook.proto.events.clean.freq</name>
<value>1d</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.llap.io.decoding.metrics.percentiles.intervals
</name>
<value>30</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
</name>
<value>1000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.jobname.length</name>
<value>50</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.mapjoin.bucket.cache.size</name>
<value>10000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.snapshot.skiplist.interval</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.support.allow.format</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.file.impl</name>
<value>org.apache.hadoop.fs.local.LocalFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>io.file.buffer.size</name>
<value>131072</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.compactor.history.reaper.interval</name>
<value>2m</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.collector-service.address</name>
<value>${yarn.nodemanager.hostname}:8048</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.balancer.block-move.timeout</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.limit.pushdown.memory.usage</name>
<value>0.04</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.lease-recheck-interval-ms</name>
<value>2000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.router.webapp.interceptor-class.pipeline</name>
<value>
org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.asynclogging</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.mmap.cache.size</name>
<value>256</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.snapshot.capture.openfiles</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.xframe.value</name>
<value>SAMEORIGIN</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.delegation.key.update-interval</name>
<value>86400000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.spark.use.ts.stats.for.mapjoin</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.vectorized.execution.mapjoin.native.multikey.only.enabled
</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.du.reserved.calculator</name>
<value>
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$ReservedSpaceCalculatorAbsolute
</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.metrics.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hiveserver2-site.xml</source>
</property>
<property>
<name>hadoop.user.group.static.mapping.overrides</name>
<value>dr.who=;</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.ha.automatic-failover.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.script.operator.truncate.env</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.client-server.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.fail-fast</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.hashtable.key.count.adjustment</name>
<value>2.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.rcfile.use.explicit.header</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.global.init.file.location</name>
<value>/usr/hdp/current/hive-server2/conf_llap/</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.read-lock-reporting-threshold-ms</name>
<value>5000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.end-notification.retry.attempts</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.ha.zkfc.port</name>
<value>8019</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.optimize.ppd.windowing</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.application-timeouts.monitor.interval-ms
</name>
<value>3000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.exec.stagingdir</name>
<value>.hive-staging</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.redundancy.considerLoad</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.client.load.resource-types.from-server</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.rest-csrf.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.schema.verification.record.version</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.in.ide.test</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.distributed-scheduling.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.prewarm.spark.timeout</name>
<value>5000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.resource-profiles.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.https.need-auth</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.ctas.external.tables</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>datanode.https.port</name>
<value>50475</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size
</name>
<value>10485760</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.balancer.getBlocks.min-block-size</name>
<value>10485760</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.async.exec.threads</name>
<value>100</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.skewjoin.compiletime</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.https.keystore.resource</name>
<value>ssl-client.xml</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.txns</name>
<value>1000000</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.timeline-client.number-of-async-entities-to-merge
</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.tez.sessions.custom.queue.allowed</name>
<value>ignore</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.webhdfs.impl</name>
<value>org.apache.hadoop.fs.WebHdfs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.http-authentication.type</name>
<value>simple</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.metastore.server.max.threads</name>
<value>100000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.auto.convert.join.hashtable.max.entries</name>
<value>21000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.notification.event.consumers</name>
<value>
org.apache.hadoop.hive.ql.cache.results.QueryResultsCache$InvalidationEventConsumer
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.loadedjobs.cache.size</name>
<value>5</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource.percentage-physical-cpu-limit
</name>
<value>80</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.recovery.dir</name>
<value>/var/log/hadoop-yarn/nodemanager/recovery-state</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.merge.sparkfiles</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.client.cache.stats.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>
/mnt/datavol/hadoop/hdfs/namenode,/hadoop/hdfs/namenode
</value>
<final>true</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.metastore.try.direct.sql.ddl</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.service.metrics.file.location</name>
<value>/tmp/report.json</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.idle.session.check.operation</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
mapreduce.input.fileinputformat.split.minsize.per.rack
</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.cluster.acls.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.client.progressmonitor.pollinterval</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>file.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-aggregation.debug-enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.search.attr.group.name
</name>
<value>cn</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
<value>0.32f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.name.cache.threshold</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.msck.repair.batch.max.retries</name>
<value>4</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.redundancy.considerLoad.factor</name>
<value>2.0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.dns.interface</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.cpu-vcores</name>
<value>3</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.exec.infer.bucket.sort.num.buckets.power.two</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.http.client.failover.sleep.max.millis</name>
<value>15000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>javax.jdo.option.DetachAllOnCommit</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.stats.ndv.estimate.percent</name>
<value>20.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.threadpool.size</name>
<value>3</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
</name>
<value>10</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.llap.auto.max.input.size</name>
<value>10737418240</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.outputcommitter.factory.scheme.s3a</name>
<value>
org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory
</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.secondary.https-address</name>
<value>0.0.0.0:9869</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.optimize.point.lookup</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.compress.output</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.strict.checks.orderby.no.limit</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.client.retry-interval-ms</name>
<value>1000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.repl.cmrootdir</name>
<value>/user/hive/cmroot/</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ipc.client.bind.wildcard.addr</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.port</name>
<value>13562</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>
hive.llap.am.liveness.connection.sleep.between.retries.ms
</name>
<value>2000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.path.style.access</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.container.liveness-monitor.interval-ms
</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
hive.llap.task.communicator.connection.sleep.between.retries.ms
</name>
<value>2000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.fslock.fair</name>
<value>false</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.llap.output.format.arrow</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exim.uri.scheme.whitelist</name>
<value>hdfs,pfile,file,s3,s3a</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.tez.bloom.filter.factor</name>
<value>1.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.lock.manager</name>
<value>
org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.zk.sm.connectionString</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:2181,ip-10-0-11-12.ap-northeast-1.compute.internal:2181,ip-10-0-11-120.ap-northeast-1.compute.internal:2181
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.display.partition.cols.separately</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.qjournal.start-segment.timeout.ms</name>
<value>20000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.auto.max.output.size</name>
<value>1073741824</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.http.numConnection</name>
<value>20</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.conf.hidden.list</name>
<value>
javax.jdo.option.ConnectionPassword,hive.server2.keystore.password,hive.druid.metadata.password
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.scheduler.maximum-allocation-mb</name>
<value>20480</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.lock.mapred.only.operation</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.orc.base.delta.ratio</name>
<value>8</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.storageinfo.defragment.timeout.ms</name>
<value>4</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.tez.task.scale.memory.reserve-fraction.min</name>
<value>0.3</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.s3guard.ddb.table.capacity.read</name>
<value>500</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.minimum-allowed-tasks</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.hbase.generatehfiles</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.group-id-plugin-classes
</name>
<value>
org.apache.hadoop.yarn.applications.distributedshell.DistributedShellTimelinePlugin
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.federation.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.tez.input.format</name>
<value>org.apache.hadoop.hive.ql.io.HiveInputFormat</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.materializedview.serde</name>
<value>org.apache.hadoop.hive.ql.io.orc.OrcSerde</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.datestring.cache.size</name>
<value>200000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.proxyuser.hdfs.groups</name>
<value>*</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.disk.balancer.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.admin.client.thread-count</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.network.counts.cache.max.size</name>
<value>2147483647</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.listen.queue.size</name>
<value>128</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.server2.close.session.on.disconnect</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs
</name>
<value>86400</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-timeline-store.path</name>
<value>/hadoop/yarn/timeline</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.job.reducer.preempt.delay.sec</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.wasb.impl</name>
<value>org.apache.hadoop.fs.azure.NativeAzureFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.ha.standby.checkpoints</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.heap.memory.monitor.usage.threshold</name>
<value>0.7</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.balancer.movedWinWidth</name>
<value>5400000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.client.thread-count</name>
<value>5</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.task.userlog.limit.kb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.query.results.cache.directory</name>
<value>/tmp/hive/_resultscache_</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.minicluster.fixed.ports</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.ui-actions.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.providers.combined</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.writer.flush-interval-seconds
</name>
<value>60</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
hive.notification.sequence.lock.retry.sleep.interval
</name>
<value>500</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.conf.restricted.list</name>
<value>
hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role,_hive.local.session.path,_hive.hdfs.session.path,_hive.tmp_table_space
</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>
dfs.namenode.block-placement-policy.default.prefer-local-node
</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.committer.staging.tmp.path</name>
<value>tmp/staging</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.mapjoin.check.memory.rows</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.ftp.data.connection.mode</name>
<value>ACTIVE_LOCAL_DATA_CONNECTION_MODE</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.dir.minimum</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.monitor.capacity.preemption.total_preemption_per_round
</name>
<value>0.1</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-blocks-per-file</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.registry.dns.bind-port</name>
<value>53</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.client.application-client-protocol.poll-interval-ms
</name>
<value>200</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions
</name>
<value>read</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.decode.partition.name</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.registry.secure</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.spark.exec.inplace.progress</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.provided.aliasmap.inmemory.batch-size</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.sensitive-config-keys</name>
<value>
secret$ password$ ssl.keystore.pass$ fs.s3.*[Ss]ecret.?[Kk]ey fs.s3a.*.server-side-encryption.key fs.azure.account.key.* credential$ oauth.*token$ hadoop.security.sensitive-config-keys
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.client.drain-entities.timeout.ms
</name>
<value>2000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.sharedcache.store.in-memory.staleness-period-mins
</name>
<value>10080</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.parquet.timestamp.skip.conversion</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.s3guard.ddb.background.sleep</name>
<value>25</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.groupby.orderby.position.alias</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.logging.operation.level</name>
<value>EXECUTION</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.compactor.compact.insert.only</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.class</name>
<value>
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hadoop.security.auth_to_local</name>
<value>DEFAULT</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.heartbeat.interval</name>
<value>3</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>dfs.http.client.failover.max.attempts</name>
<value>15</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.bind.host</name>
<value>ip-10-0-11-101.ap-northeast-1.compute.internal</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>mapreduce.task.profile.params</name>
<value>
-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.address</name>
<value>0.0.0.0:45454</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-xattr-size</name>
<value>16384</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.java.opts</name>
<value>-Xmx4096m</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource-plugins.gpu.docker-plugin
</name>
<value>nvidia-docker-v1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.store.leveldb.path</name>
<value>/hadoop/mapreduce/jhs</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.shuffle.connection-keep-alive.enable</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.stats.deserialization.factor</name>
<value>10.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.thrift.framed.transport.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.localizer.cache.cleanup.interval-ms
</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.webapp.api-service.enable</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.intermediate-data-encryption.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.client.cache.max.capacity</name>
<value>50</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.node-removal-untracked.timeout-ms
</name>
<value>60000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.optimize.shared.work.extended</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.write.stale.datanode.ratio</name>
<value>1.0f</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.server2.authentication.ldap.groupClassKey</name>
<value>groupOfNames</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.rm.container-allocation.expiry-interval-ms
</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.exec.script.maxerrsize</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.compactor.history.retention.attempted</name>
<value>2</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ha.failover-controller.cli-check.rpc-timeout.ms</name>
<value>20000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.cleaner.period-mins</name>
<value>1440</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.proxyuser.root.groups</name>
<value>*</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.llap.io.trace.size</name>
<value>2Mb</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.llap.task.scheduler.num.schedulable.tasks.per.node
</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>io.erasurecode.codec.rs.rawcoders</name>
<value>rs_native,rs_java</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.snapshot.skiplist.max.levels</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.placement-constraints.scheduler.pool-size
</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.threads.keepalivetime</name>
<value>60</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.minicluster.use-rpc</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.optimize.sort.dynamic.partition</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.cluster.administrators</name>
<value> hadoop</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.ha.tail-edits.in-progress</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.pre.hooks</name>
<value>
org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.federation.state-store.class</name>
<value>
org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.io.encode.vector.serde.async.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.sync.behind.writes.in.background</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.collector-service.thread-count</name>
<value>5</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.security.metastore.authorization.auth.reads</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.s3a.committer.staging.abort.pending.uploads</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.committer.magic.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.node-labels.provider.fetch-interval-ms
</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.sasl.qop</name>
<value>auth</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.zookeeper.session.timeout</name>
<value>1200000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.retry.policy.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>nfs.file.dump.dir</name>
<value>/tmp/.hdfs-nfs</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.server2.thrift.max.message.size</name>
<value>104857600</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.metadata.db.type</name>
<value>mysql</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.orderby.position.alias</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.nodemanager-connect-retries</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.stats.ndv.densityfunction</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.tez.container.max.java.heap.fraction</name>
<value>0.8</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.jobname.limit</name>
<value>50</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
</name>
<value>10000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.metastore.aggregate.stats.cache.size</name>
<value>10000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.memory.size</name>
<value>9663676416</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.webhdfs.ugi.expire.after.access</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.list.cache.directives.num.responses</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.blockreport.initialDelay</name>
<value>120</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.query.results.cache.max.entry.lifetime</name>
<value>3600s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.in.test</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.speculative.retry-after-no-speculate</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.am.liveness.heartbeat.interval.ms</name>
<value>10000ms</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.metastore.client.cache.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.resource.memory.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.exec.rowoffset</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.intermediate-done-dir</name>
<value>/mr-history/tmp</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.map.cpu.vcores</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.azure.sas.expiry.period</name>
<value>90d</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>datanucleus.plugin.pluginRegistryBundleCheck</name>
<value>LOG</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.llap.external.splits.temp.table.storage.format
</name>
<value>orc</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.leveldb-timeline-store.read-cache-size
</name>
<value>104857600</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.blockreport.split.threshold</name>
<value>1000000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.arrow.batch.allocator.limit</name>
<value>10000000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.journalnode.edits.dir</name>
<value>/hadoop/hdfs/journalnode</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>fs.s3a.block.size</name>
<value>64M</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.llap.io.row.wrapper.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.select.threshold</name>
<value>10000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.registry.zk.connection.timeout.ms</name>
<value>15000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.webapp.address</name>
<value>0.0.0.0:8788</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.enforce.bucketmapjoin</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.edekcacheloader.interval.ms</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.generic-application-history.save-non-am-container-meta-info
</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.max.start.attempts</name>
<value>5</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.mover.keytab.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.client.resolve.topology.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.resource.checked.volumes.minimum</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.vectorized.input.format.supports.enabled</name>
<value>decimal_64</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ftp.replication</name>
<value>3</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.delegation-token.max-conf-size-bytes
</name>
<value>12800</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>io.compression.codec.bzip2.library</name>
<value>system-native</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.cbo.costmodel.local.fs.read</name>
<value>4.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.retry-delay.max.ms</name>
<value>60000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.client.user</name>
<value>anonymous</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.service.metrics.hadoop2.component</name>
<value>hiveserver2</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hiveserver2-site.xml</source>
</property>
<property>
<name>hive.spark.client.rpc.threads</name>
<value>8</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.constraint.notnull.enforce</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.app.mapreduce.shuffle.log.limit.kb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.repl.cm.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.metrics.runtime.buckets</name>
<value>60,300,1440</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint
</name>
<value>http://localhost:3476/v1.0/docker/cli</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.cache-store-class
</name>
<value>
org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.generic-application-history.store-class
</name>
<value>
org.apache.hadoop.yarn.server.applicationhistoryservice.NullApplicationHistoryStore
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.active.passive.ha.enable</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.druid.storage.storageDirectory</name>
<value>/druid/segments</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.key.default.bitlength</name>
<value>128</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.join.inner.residual</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>datanucleus.schema.validateColumns</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.io.sarg.cache.max.weight.mb</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.max.worker.threads</name>
<value>500</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.vectorized.groupby.maxentries</name>
<value>1000000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.task.timeout</name>
<value>300000</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.optimize.constant.propagation</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
hive.metastore.disallow.incompatible.col.type.changes
</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.cli.print.escape.crlf</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.store.class</name>
<value>
org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hadoop.security.groups.cache.warn.after.ms</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.fetch.thread-count</name>
<value>4</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.druid.passiveWaitTimeMs</name>
<value>30000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.strict.checks.cartesian.product</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.input.buffer.percent</name>
<value>0.7</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>/mnt/datavol/hadoop/hdfs/data,/hadoop/hdfs/data</value>
<final>true</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>dfs.namenode.accesstime.precision</name>
<value>0</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
dfs.namenode.decommission.max.concurrent.tracked.nodes
</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.avoid.write.stale.datanode</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
yarn.minicluster.yarn.nodemanager.resource.memory-mb
</name>
<value>4096</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-executor.class</name>
<value>
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.use.SSL</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.exec.script.allow.partial.consumption</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.privilege.synchronizer</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.object.cache.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.windows-container.cpu-limit.enabled
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
dfs.client.write.exclude.nodes.cache.expiry.interval.millis
</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hive.metastore.aggregate.stats.cache.max.partitions
</name>
<value>10000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.fs.state-store.num-retries</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.cbo.costmodel.hdfs.read</name>
<value>1.5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.assumed.role.credentials.provider</name>
<value>
org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.local-fs.single-disk-limit.bytes</name>
<value>-1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>datanucleus.connectionPoolingType</name>
<value>HikariCP</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server.tcp.keepalive</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.security.authorization.sqlstd.confwhitelist</name>
<value>
hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.druid\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\.max\.dynamic\.partitions.*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.exec\.parallel.*|hive\.explain\..*|hive\.fetch.task\..*|hive\.groupby\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.join\..*|hive\.limit\..*|hive\.log\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.parquet\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.server2\.thrift\.resultset\.default\.fetch\.size|hive\.server2\.proxy\.user|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.strict\..*|hive\.tez\..*|hive\.vectorized\..*|fs\.defaultFS|ssl\.client\.truststore\.location|distcp\.atomic|distcp\.ignore\.failures|distcp\.preserve\.status|distcp\.preserve\.rawxattrs|distcp\.sync\.folders|distcp\.delete\.missing\.source|distcp\.keystore\.resource|distcp\.liststatus\.threads|distcp\.max\.maps|distcp\.copy\.strategy|distcp\.skip\.crc|distcp\.copy\.overwrite|distcp\.copy\.append|distcp\.map\.bandwidth\.mb|distcp\.dynamic\..*|distcp\.meta\.folder|distcp\.copy\.listing\.class|distcp\.filters\.class|distcp\.options\.skipcrccheck|distcp\.options\.m|distcp\.options\.numListstatusThreads|distcp\.options\.mapredSslConf|distcp\.options\.bandwidth|distcp\.options\.overwrite|distcp\.options\.strategy|distcp\.options\.i|distcp\.options\.p.*|distcp\.options\.update|distcp\.options\.delete|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapred\.job\.queue\.name|mapred\.output\.compression\.type|mapred\.min\.split\.size|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.job\.tags|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|mapreduce\.output\.fileoutputformat\.compress\.codec|mapreduce\.output\.fileoutputformat\.compress\.type|oozie\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|tez\.queue\.name|hive\.transpose\.aggr\.join|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.default\.fileformat\.managed|hive\.enforce\.bucketmapjoin|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.query\.result\.fileformat|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.cli\.tez\.session\.async|hive\.compat|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exec\.copyfile\.maxsize|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.query\.results\.cache\.enabled|hive\.query\.results\.cache\.wait\.for\.pending\.results|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.exec\.schema\.evolution|hive\.server2\.logging\.operation\.level|hive\.server2\.thrift\.resultset\.serialize\.in\.tasks|hive\.support\.special\.characters\.tablename|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.llap\.io\.enabled|hive\.llap\.io\.use\.fileid\.path|hive\.llap\.daemon\.service\.hosts|hive\.llap\.execution\.mode|hive\.llap\.auto\.allow\.uber|hive\.llap\.auto\.enforce\.tree|hive\.llap\.auto\.enforce\.vectorized|hive\.llap\.auto\.enforce\.stats|hive\.llap\.auto\.max\.input\.size|hive\.llap\.auto\.max\.output\.size|hive\.llap\.skip\.compile\.udf\.check|hive\.llap\.client\.consistent\.splits|hive\.llap\.enable\.grace\.join\.in\.llap|hive\.llap\.allow\.permanent\.fns|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.reorder\.nway\.joins|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout|hive\.query\.id
</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>dfs.datanode.use.datanode.hostname</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.create.as.insert.only</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.server2.tez.sessions.per.default.queue</name>
<value>1</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>file.blocksize</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ipc.client.kill.max</name>
<value>10</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.metastore.schema.verification</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.nodemanager.minimum.version</name>
<value>NONE</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.list.cache.pools.num.responses</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.service.metrics.class</name>
<value>
org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.batch.retrieve.max</name>
<value>300</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.cache.revocation.polling.ms</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.aux-services.timeline_collector.class
</name>
<value>
org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.querylog.location</name>
<value>/tmp/hive</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.rpc.port</name>
<value>0</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.http.logs.enabled</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.vectorized.use.vectorized.input.format</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.load.dynamic.partitions.thread</name>
<value>15</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.read.shortcircuit.streams.cache.size</name>
<value>4096</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.reader.webapp.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8198
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.hook.proto.events.ttl</name>
<value>7d</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.router.pipeline.cache-max-size</name>
<value>25</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.ls.limit</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>io.mapfile.bloom.size</name>
<value>1048576</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.support.quoted.identifiers</name>
<value>column</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.vcpus.per.instance</name>
<value>3</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.scheduler.queue-placement-rules</name>
<value>user-group</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>seq.io.sort.mb</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.exit.timeout</name>
<value>60000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>net.topology.impl</name>
<value>org.apache.hadoop.net.NetworkTopology</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.task.scheduler.preempt.independent</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.node-labels.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.trash.checkpoint.interval</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.tez.dynamic.semijoin.reduction.threshold</name>
<value>0.5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.http.cookie.max.age</name>
<value>86400s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.app.mapreduce.client.max-retries</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.maps</name>
<value>2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.optimize.limittranspose.reductiontuples</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
</name>
<value>10000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.zookeeper.namespace</name>
<value>hiveserver2-interactive</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.resources-handler.class
</name>
<value>
org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.strict.checks.no.partition.filter</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.failover.random.order</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.maxattempts</name>
<value>4</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.http.cookie.is.secure</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.acl-view-job</name>
<value> </value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>fs.s3a.user.agent.prefix</name>
<value>
User-Agent: APN/1.0 Hortonworks/1.0 HDP/3.0.1.0-187
</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.dir</name>
<value>/hadoop/hdfs/namesecondary</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.lazysimple.extended_boolean_literal</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.use.ipc.callq</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.http.authentication.type</name>
<value>simple</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.exec.schema.evolution</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.limittranspose</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.java.secure.random.algorithm</name>
<value>SHA1PRNG</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.stats.autogather</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.metastore.initial.metadata.count.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.resource.du.reserved</name>
<value>104857600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.orc.splits.ms.footer.cache.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.vectorized.row.serde.inputformat.excludes</name>
<value>
org.apache.parquet.hadoop.ParquetInputFormat,org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ipc.server.log.slow.rpc</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.disk-health-checker.min-healthy-disks
</name>
<value>0.25</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.job.max.map</name>
<value>-1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.optimize.dynamic.partition.hashjoin</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.mapjoin.hybridgrace.bloomfilter</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.retry.window.base</name>
<value>3000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.address</name>
<value>${yarn.nodemanager.hostname}:8040</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.viewfs.impl</name>
<value>org.apache.hadoop.fs.viewfs.ViewFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.metastore.warehouse.dir</name>
<value>/warehouse/tablespace/managed/hive</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.repl.approx.max.load.tasks</name>
<value>10000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.map.output.collector.class</name>
<value>org.apache.hadoop.mapred.MapTask$MapOutputBuffer</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.ttl-ms</name>
<value>2678400000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.server2.thrift.http.request.header.size</name>
<value>6144</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.acl.provider.permission.pattern</name>
<value>
^(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?(,(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?)*$
</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.opportunistic-container-allocation.nodes-used
</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.stats.column.autogather</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.plugin.client.num.threads</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold
</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.admin.thread-count</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.test.bucketcodec.version</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.task.communicator.listener.thread-count</name>
<value>30</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>tfile.io.chunk.size</name>
<value>1048576</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.entity.separator</name>
<value>@</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.task.combine.progress.records</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.exec.local.scratchdir</name>
<value>/tmp/hive</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.cleaner.initial-delay-mins</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.query.results.cache.max.size</name>
<value>2147483648</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.abfss.impl</name>
<value>
org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.provided.aliasmap.text.delimiter</name>
<value>,</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.ftp.host.port</name>
<value>21</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.tez.sessions.restricted.configs</name>
<value>hive.execution.mode,hive.execution.engine</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
hive.query.results.cache.nontransactional.tables.enabled
</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.committer.setup.cleanup.needed</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.hostname</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.hbase.file.metadata.threads</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.bitmap.type</name>
<value>roaring</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.limit.row.max.size</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>javax.jdo.option.Multithreaded</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.mapjoin.hybridgrace.minnumpartitions</name>
<value>16</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.session.check.interval</name>
<value>6h</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.write.byte-array-manager.count-limit</name>
<value>2048</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.timedout.txn.reaper.start</name>
<value>100s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.client.cache.expiry.time</name>
<value>120s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.downloaded.resources.dir</name>
<value>/tmp/${hive.session.id}_resources</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.kms.client.timeout</name>
<value>60</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.leveldb-state-store.path</name>
<value>${hadoop.tmp.dir}/yarn/system/rmstore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.keytab</name>
<value>/etc/security/keytab/jhs.service.keytab</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms
</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.zookeeper.connection.basesleeptime</name>
<value>1000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ha.health-monitor.connect-retry-interval.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>manage.include.files</name>
<value>false</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.opportunistic-containers-use-pause-for-preemption
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.key.provider.cache.expiry</name>
<value>864000000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.webapp.rest-csrf.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.exec.infer.bucket.sort</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.max.objects</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.max.full.block.report.leases</name>
<value>6</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.ec.reconstruction.threads</name>
<value>8</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.ignore.mapjoin.hint</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.tez.dynamic.semijoin.reduction.for.mapjoin</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.am.liveness.connection.timeout.ms</name>
<value>10000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.amlauncher.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.archive.intermediate.archived</name>
<value>_INTERMEDIATE_ARCHIVED</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.socketcache.capacity</name>
<value>16</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>nfs.wtmax</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.repl.cm.interval</name>
<value>3600s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.mm.avoid.s3.globstatus</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.zookeeper.client.port</name>
<value>2181</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.scheduler.configuration.store.class</name>
<value>file</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.webapp.xfs-filter.xframe-options</name>
<value>SAMEORIGIN</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.block.write.retries</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.acl.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.query.results.cache.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.resource-monitor.interval-ms</name>
<value>3000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.assumed.role.session.duration</name>
<value>30m</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.recovery.supervised</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
hive.vectorized.execution.mapjoin.overflow.repeated.threshold
</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.orm.retrieveMapNullsAsEmptyStrings</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.adl.oauth2.access.token.provider.type</name>
<value>ClientCredential</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.streaming.auto.flush.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.AbstractFileSystem.hdfs.impl</name>
<value>org.apache.hadoop.fs.Hdfs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.quota.by.storage.type.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.service.metrics.reporter</name>
<value>HADOOP2</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hiveserver2-site.xml</source>
</property>
<property>
<name>hive.metastore.aggregate.stats.cache.max.variance</name>
<value>0.01</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.credential.provider.path</name>
<value>
jceks://file/usr/hdp/current/hive-server2/conf_llap/hive-site.jceks
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.compactor.worker.threads</name>
<value>1</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.strict.checks.bucketing</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.event.db.notification.api.auth</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.analyze.stmt.collect.partlevel.stats</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.dump.include.acid.tables</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.block.scanner.volume.bytes.per.second</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-component-length</name>
<value>255</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.map.aggr.hash.percentmemory</name>
<value>0.5</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.explain.user</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.http.client.retry.policy.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.complete.cancel.delegation.tokens</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.cache.limit.max-resources</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapred.bin.path</name>
<value>/usr/hdp/current/hadoop-client/bin/mapred</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.broker.address.default</name>
<value>localhost:8082</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.io.rcfile.record.buffer.size</name>
<value>4194304</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.recovery.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
hive.metastore.aggregate.stats.cache.max.reader.wait
</name>
<value>1000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.coordinator.address.default</name>
<value>localhost:8082</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.map.output.compress.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.optimize.shared.work</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.enable.doAs</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.hmshandler.retry.attempts</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.AbstractFileSystem.har.impl</name>
<value>org.apache.hadoop.fs.HarFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.placement-constraints.algorithm.iterator
</name>
<value>SERIAL</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.process-kill-wait.ms</name>
<value>5000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
hive.server2.authentication.ldap.groupMembershipKey
</name>
<value>member</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ha.zookeeper.parent-znode</name>
<value>/hadoop-ha</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.smbjoin.cache.rows</name>
<value>10000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.hbase.wal.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.admin.acl</name>
<value>activity_analyzer,yarn</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.llap.io.track.cache.usage</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.logging.operation.log.location</name>
<value>/tmp/hive/operation_logs</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.llap.io.vrb.queue.limit.min</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.tez.default.queues</name>
<value>default</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.service.system-service.dir</name>
<value>/services</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.zk-appid-node.split-index</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.threads.max</name>
<value>20</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.state-store.max-completed-applications
</name>
<value>${yarn.resourcemanager.max-completed-applications}</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.vectorized.if.expr.mode</name>
<value>better</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.etag.checksum.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.peer.stats.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.am-reporter.max.threads</name>
<value>4</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.AbstractFileSystem.ftp.impl</name>
<value>org.apache.hadoop.fs.ftp.FtpFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>_hive.local.session.path</name>
<value>/tmp/hive/589fe63b-b5be-46bd-b009-b9844af3bcf3</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>ipc.client.idlethreshold</name>
<value>8000</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.metastore.thrift.compact.protocol.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.compactor.initiator.failed.compacts.threshold</name>
<value>2</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ftp.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.druid.metadata.username</name>
<value>druid</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.count.open.txns.interval</name>
<value>1s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.mapjoin.hybridgrace.memcheckfrequency</name>
<value>1024</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.start.cleanup.scratchdir</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.socket.send.buffer.size</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hive.security.authorization.createtable.owner.grants
</name>
<value>INSERT,SELECT,UPDATE,DELETE</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>dfs.provided.aliasmap.inmemory.leveldb.dir</name>
<value>/tmp</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.posix.acl.inheritance.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.aggregate.stats.cache.clean.until</name>
<value>0.8</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.metadatastore.authoritative</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.support.dynamic.service.discovery</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.vectorized.groupby.flush.percent</name>
<value>0.1</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.disk.balancer.block.tolerance.percent</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.drop.ignorenonexistent</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.sleep.time</name>
<value>PT10S</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.auto.allow.uber</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>ipc.client.connection.maxidletime</name>
<value>30000</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.merge.smallfiles.avgsize</name>
<value>16000000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.metastore.connect.retries</name>
<value>24</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.common.configuration.version</name>
<value>3.0.0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.acl</name>
<value>*</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.mover.retry.max.attempts</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.ifile.readahead.bytes</name>
<value>4194304</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>io.map.index.interval</name>
<value>128</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.disk.balancer.max.disk.throughputInMBperSec</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.daemon.yarn.shuffle.port</name>
<value>15551</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.mover.moverThreads</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.tez.session.lifetime</name>
<value>162h</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
</name>
<value>300000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>javax.jdo.option.ConnectionURL</name>
<value>
jdbc:mysql://ip-10-0-11-101.ap-northeast-1.compute.internal/hive?createDatabaseIfNotExist=true
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices
</name>
<value>auto</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.exec.show.job.failure.debug.info</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.vectorized.execution.mapjoin.native.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>tfile.fs.output.buffer.size</name>
<value>262144</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.resource.use.hdfs.location</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.search.attr.member
</name>
<value>member</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.qjournal.queued-edits.limit.mb</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.health-checker.script.timeout-ms</name>
<value>60000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.tez.initialize.default.sessions</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.handler.count</name>
<value>100</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.optimize.limittranspose.reductionpercentage</name>
<value>1.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.ha.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.security.authenticator.manager</name>
<value>
org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.tez.max.partition.factor</name>
<value>2.0</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.join.emit.interval</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.port</name>
<value>10500</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.vectorized.use.vector.serde.deserialize</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.fs-limits.min-block-size</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.with-user-dir
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.handler.count</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.http.internal-proxy.port</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.stats.filter.in.factor</name>
<value>1.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.mapjoin.followby.gby.localtask.max.memory.usage
</name>
<value>0.55</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.orc.splits.ms.footer.cache.ppd.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.app.attempt.diagnostics.limit.kc</name>
<value>64</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.sample.seednumber</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.default.fileformat.managed</name>
<value>ORC</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.connect.retry-interval.ms</name>
<value>30000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.optimize.ppd.storage</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.hostname</name>
<value>ip-10-0-11-101.ap-northeast-1.compute.internal</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.datanode.socket.reuse.keepalive</name>
<value>4000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>nfs.dump.dir</name>
<value>/tmp/.hdfs-nfs</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.spark.client.future.timeout</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.webui.use.spnego</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.script.auto.progress</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.parallel.thread.number</name>
<value>8</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.retrycache.heap.percent</name>
<value>0.03f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.xattrs.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.txn.store.impl</name>
<value>
org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.container-localizer.java.opts</name>
<value>-Xmx256m</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.quota.init-threads</name>
<value>4</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-container-queuing.queue-limit-stdev
</name>
<value>1.0f</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.webapp.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:19888
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.llap.daemon.output.service.send.buffer.size</name>
<value>131072</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.speculative.slowtaskthreshold</name>
<value>1.0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8050
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.exec.submitviachild</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.map.aggr.hash.force.flush.memory.threshold</name>
<value>0.9</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>datanucleus.fixedDatastore</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.s3a.connection.timeout</name>
<value>200000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.io.allocator.alloc.min</name>
<value>4Kb</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.in.tez.test</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.orc.compute.splits.num.threads</name>
<value>20</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.remove.orderby.in.subquery</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.block.access.token.enable</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.metastore.sasl.enabled</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
</name>
<value>86400</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.druid.metadata.base</name>
<value>druid</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.map.sort.spill.percent</name>
<value>0.7</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.job.end-notification.max.attempts</name>
<value>5</value>
<final>true</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.safemode.extension</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.management.acl</name>
<value>*</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.script.serde</name>
<value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.tez.session.lifetime.jitter</name>
<value>3h</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.materializedview.rewriting.strategy</name>
<value>heuristic</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.heartbeat.interval</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.redundancy.interval.seconds</name>
<value>3s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>llap.shuffle.connection-keep-alive.enable</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.mapred.local.mem</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.merge.cardinality.check</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.content-summary.limit</name>
<value>5000</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.store-class</name>
<value>
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>javax.jdo.option.ConnectionDriverName</name>
<value>com.mysql.jdbc.Driver</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.task.profile.reduces</name>
<value>0-2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.journal-plugin.qjournal</name>
<value>
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
dfs.namenode.reencrypt.throttle.limit.updater.ratio
</name>
<value>1.0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.fd-retain-secs</name>
<value>300</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.groupby.position.alias</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.failure.hooks</name>
<value>
org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.tez.dynamic.partition.pruning.max.data.size</name>
<value>104857600</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.search.group.hierarchy.levels
</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.nodes.exclude-path</name>
<value>/etc/hadoop/conf/yarn.exclude</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
ha.failover-controller.graceful-fence.connection.retries
</name>
<value>1</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.bind-host</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.llap.io.encode.slice.lrr</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.llap.task.scheduler.node.reenable.max.timeout.ms
</name>
<value>10000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.index.filter</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.rpc-address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8020
</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.mapjoin.localtask.max.memory.usage</name>
<value>0.9</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold
</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.exim.test.mode</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.decommission.blocks.per.interval</name>
<value>500000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.image.compress</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.materializedview.rewriting</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.materializedview.fileformat</name>
<value>ORC</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.am.liveness-monitor.expiry-interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.ubertask.maxreduces</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.safemode.min.datanodes</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.attempts.maximum</name>
<value>20</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore
</name>
<value>GET,OPTIONS,HEAD</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>parquet.memory.pool.ratio</name>
<value>0.5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.use.orc.codec.pool</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.move.interval-ms</name>
<value>180000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.caller.context.max.size</name>
<value>128</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.tez.bucket.pruning.compat</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.uris</name>
<value>
thrift://ip-10-0-11-101.ap-northeast-1.compute.internal:9083
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.server2.parallel.ops.in.session</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.test.fail.compaction</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.multipart.size</name>
<value>67108864</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.compactor.initiator.on</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.registry.class</name>
<value>
org.apache.hadoop.registry.client.impl.FSRegistryOperationsService
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.mapjoin.smalltable.filesize</name>
<value>25000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.wait.queue.comparator.class.name</name>
<value>
org.apache.hadoop.hive.llap.daemon.impl.comparator.ShortestJobFirstComparator
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.leader.zookeeper.namespace</name>
<value>hiveserver2-leader</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.client.connect.retry.delay</name>
<value>5s</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.edit.log.transfer.timeout</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
</name>
<value>90</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.shuffle.ssl.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.backup.address</name>
<value>0.0.0.0:50100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
</name>
<value>nobody</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.check.period</name>
<value>60s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>nfs.allow.insecure.ports</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.ats.hook.queue.capacity</name>
<value>64</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.cache.expr.evaluation</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.ssl.protocol.blacklist</name>
<value>SSLv2,SSLv3</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.delegation.token.always-use</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.transfer.socket.send.buffer.size</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>net.topology.node.switch.mapping.impl</name>
<value>org.apache.hadoop.net.ScriptBasedMapping</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.client.retry.limit</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.acid</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.resource.count-logical-processors-as-cores
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.io.encode.vector.serde.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.max.created.files</name>
<value>100000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.swift.impl</name>
<value>
org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.exec.scratchdir</name>
<value>/tmp/hive</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.delegation.token.max-lifetime</name>
<value>604800000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.shuffle.log.backups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.llap.skip.compile.udf.check</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.dump.metadata.only</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.partitions.dump.parallelism</name>
<value>100</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>datanucleus.rdbms.useLegacyNativeValueStrategy</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.oauth2.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
dfs.namenode.edit.log.autoroll.multiplier.threshold
</name>
<value>2.0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.container-metrics.unregister-delay-ms
</name>
<value>60000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.transactional.events.mem</name>
<value>10000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.timedout.txn.reaper.interval</name>
<value>180s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.user.provider.user.pattern</name>
<value>^[A-Za-z_][A-Za-z0-9._-]*[$]?$</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.defaultFS</name>
<value>
hdfs://ip-10-0-11-101.ap-northeast-1.compute.internal:8020
</value>
<final>true</final>
<source>core-site.xml</source>
</property>
<property>
<name>fs.s3a.socket.recv.buffer</name>
<value>8192</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.merge.inmem.threshold</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.provided.aliasmap.class</name>
<value>
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap
</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.driver.parallel.compilation</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.router.webapp.address</name>
<value>0.0.0.0:8089</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds
</name>
<value>3600</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.writer.class</name>
<value>
org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
</name>
<value>0.75f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.security.metastore.authenticator.manager</name>
<value>
org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.runtime.linux.allowed-runtimes</name>
<value>default,docker</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.abfs.impl</name>
<value>org.apache.hadoop.fs.azurebfs.Abfs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>io.map.index.skip</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
dfs.secondary.namenode.kerberos.internal.spnego.principal
</name>
<value>${dfs.web.authentication.kerberos.principal}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.rpc.query.plan</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.dumpdir.ttl</name>
<value>7d</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms
</name>
<value>20</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.resource.mb</name>
<value>5120</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.serdes.using.metastore.for.schema</name>
<value>
org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.stats.num.nulls.estimate.percent</name>
<value>5.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.session.history.enabled</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.ppd.recognizetransivity</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.provided.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.tasklog.debug.timeout</name>
<value>20000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.disk-health-checker.interval-ms</name>
<value>120000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.versions</name>
<value>1.5f,2.0f</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.reduce.memory.mb</name>
<value>10240</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.job.maxtaskfailures.per.tracker</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.llap.io.allocator.mmap</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.block.placement.ec.classname</name>
<value>
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant
</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jvm.system-properties-to-log</name>
<value>
os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name
</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.tez.input.generate.consistent.splits</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.security.crypto.buffer.size</name>
<value>8192</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-metrics.period-ms</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.scheduler.minimum-allocation-vcores</name>
<value>1</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.keytab</name>
<value>/etc/krb5.keytab</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.cgroups.hierarchy
</name>
<value>/hadoop-yarn</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.vectorized.adaptor.usage.mode</name>
<value>all</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.fs.state-store.retry-interval-ms
</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ipc.maximum.response.length</name>
<value>134217728</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.io.trace.always.dump</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.http.worker.keepalive.time</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.table.type.mapping</name>
<value>CLASSIC</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.exec.job.debug.timeout</name>
<value>30000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.rcfile.use.sync.cache</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>
mapreduce_shuffle,spark2_shuffle,timeline_collector
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.optimize.correlation</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.transactional.concatenate.noblock</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>io.compression.codecs</name>
<value>
org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec
</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.webapp.xfs-filter.xframe-options
</name>
<value>SAMEORIGIN</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.split.metainfo.maxsize</name>
<value>10000000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.exec.mode.local.auto</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.scheduler.configuration.zk-store.parent-path</name>
<value>/confstore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.skewjoin.mapjoin.min.split</name>
<value>33554432</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.share.object.pools</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.log-aggregation.file-formats</name>
<value>TFile</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.logaggregation.threadpool-size-max
</name>
<value>100</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.limit.partition.request</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.management.rpc.port</name>
<value>15004</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms
</name>
<value>100</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.tez.min.partition.factor</name>
<value>0.25</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.read.timeout</name>
<value>180000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.task.container.log.backups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.abfss.impl</name>
<value>org.apache.hadoop.fs.azurebfs.Abfss</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.stats.gather.num.threads</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.entity.capture.transform</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.s3guard.ddb.table.capacity.write</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ipc.client.connect.max.retries</name>
<value>50</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hadoop.service.shutdown.timeout</name>
<value>30s</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.webapp.https.address</name>
<value>0.0.0.0:8044</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.store.class</name>
<value>
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.metastore.fastpath</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.metadata.uri</name>
<value>jdbc:mysql://localhost:3355/druid</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.druid.indexer.partition.size.max</name>
<value>1000000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.auto.convert.join.noconditionaltask</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.exec.perf.logger</name>
<value>org.apache.hadoop.hive.ql.log.PerfLogger</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.min.worker.threads</name>
<value>5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.service.refresh.interval.sec</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.rm.system-metrics-publisher.emit-container-events
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.spark.dynamic.partition.pruning</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.max.transfer.threads</name>
<value>4096</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.metastore.rawstore.impl</name>
<value>org.apache.hadoop.hive.metastore.ObjectStore</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed
</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.log.every.n.records</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>atlas.hook.hive.minThreads</name>
<value>1</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.datanode.metrics.logger.period.seconds</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.tez.dynamic.partition.pruning</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.optimize.bucketmapjoin</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.http.authentication.token.validity</name>
<value>36000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.io.allocator.alloc.max</name>
<value>16Mb</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.tez.max.bloom.filter.entries</name>
<value>100000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>
ip-10-0-11-12.ap-northeast-1.compute.internal:50090
</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hadoop.fuse.timer.period</name>
<value>5</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.client.failover-proxy-provider</name>
<value>
org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.oob.timeout-ms</name>
<value>1500,0,0,0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.container-diagnostics-maximum-size
</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resourcemanager.minimum.version</name>
<value>NONE</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.map.skip.maxrecords</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.compactor.delta.num.threshold</name>
<value>10</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.scheduler.configuration.leveldb-store.path</name>
<value>${hadoop.tmp.dir}/yarn/system/confstore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.top.num.users</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.application.classpath</name>
<value>
$HADOOP_CONF_DIR,/usr/hdp/3.0.1.0-187/hadoop/*,/usr/hdp/3.0.1.0-187/hadoop/lib/*,/usr/hdp/current/hadoop-hdfs-client/*,/usr/hdp/current/hadoop-hdfs-client/lib/*,/usr/hdp/current/hadoop-yarn-client/*,/usr/hdp/current/hadoop-yarn-client/lib/*
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.s3a.metadatastore.impl</name>
<value>org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>atlas.hook.hive.maxThreads</name>
<value>1</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.configuration.provider-class</name>
<value>org.apache.hadoop.yarn.LocalConfigurationProvider</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.resultset.serialize.in.tasks</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.localize.resource.num.wait.attempts</name>
<value>5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.txn.stats.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.point.lookup.min</name>
<value>31</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
<final>true</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/tmp/hadoop-${user.name}</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.task.scheduler.locality.delay</name>
<value>8000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.metastore.client.capability.check</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.query.results.cache.max.entry.size</name>
<value>10485760</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.https.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8090
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.enforce.sortmergebucketmapjoin</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.limit.optimize.limit.file</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.query.results.cache.wait.for.pending.results</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.ec.policies.max.cellsize</name>
<value>4194304</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.done-dir
</name>
<value>/ats/done/</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms
</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.tez.cartesian-product.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.avoid.read.stale.datanode</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.test.vectorized.execution.enabled.override</name>
<value>none</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.web.port</name>
<value>15002</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.cluster.local.dir</name>
<value>/hadoop/mapred,/mnt/datavol/hadoop/mapred</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.move.thread-count</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>datanucleus.rdbms.initializeColumnInfo</name>
<value>NONE</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.store.in-memory.check-period-mins</name>
<value>720</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.multipart.threshold</name>
<value>2147483647</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.cli.prompt</name>
<value>hive</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.cache.pinobjtypes</name>
<value>Table,Database,Type,FieldSchema,Order</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.hmshandler.force.reload.conf</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.combine.equivalent.work.optimization</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.fs.handler.class</name>
<value>
org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.legacy.schema.for.all.serdes</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.rpc.num.handlers</name>
<value>5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.checkpoint.period</name>
<value>21600</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.spark.job.monitor.timeout</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.kms.client.encrypted.key.cache.low-watermark
</name>
<value>0.3f</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.replication</name>
<value>3</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
dfs.namenode.datanode.registration.ip-hostname-check
</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.auto.auth</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
mapreduce.job.reducer.unconditional-preempt.delay.sec
</name>
<value>300</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.datanode.shared.file.descriptor.paths</name>
<value>/dev/shm,/tmp</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.check.quiet-multiplier</name>
<value>1.5</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.recovery.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.metastore.execute.setugi</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.aux-services.spark_shuffle.classpath
</name>
<value>/usr/hdp/${hdp.version}/spark/aux/*</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hadoop.security.instrumentation.requires.admin</name>
<value>false</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.namenode.startup.delay.block.deletion.sec</name>
<value>3600</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.resource-tracker.client.thread-count
</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.stats.reliable</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ha.failover-controller.new-active.rpc-timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.support.concurrency</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>ipc.server.max.connections</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.tez.queue.access.check</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.app.mapreduce.am.job.task.listener.thread-count
</name>
<value>30</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>datanucleus.connectionPool.maxPoolSize</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.disable.unsafe.external.table.operations</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.resource.detect-hardware-capabilities
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.scheduler.maximum-allocation-vcores</name>
<value>3</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>net.topology.script.number.args</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource.system-reserved-memory-mb
</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.socket.send.buffer</name>
<value>8192</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed
</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.allowed-container-networks
</name>
<value>host,none,bridge</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.reduce.cpu.vcores</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ftp.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.int.timestamp.conversion.in.seconds</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.client.nodemanager-connect.max-wait-ms</name>
<value>60000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.snapshotdiff.listing.limit</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.rpc.socket.factory.class.default</name>
<value>org.apache.hadoop.net.StandardSocketFactory</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.io.allocator.discard.method</name>
<value>both</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.hbase.coprocessor.jar.hdfs.location
</name>
<value>
file:///usr/hdp/3.0.1.0-187/hadoop-yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor.jar
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.reconstruction.pending.timeout-sec</name>
<value>300</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.dns.log-slow-lookups.threshold.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ha.zookeeper.acl</name>
<value>world:anyone:rwcda</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.idle.session.timeout</name>
<value>1d</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.security.groups.cache.background.reload</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.caller.context.signature.max.size</name>
<value>40</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.mapjoin.optimized.hashtable.wbsize</name>
<value>8388608</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ipc.client.connect.retry.interval</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.speculative</name>
<value>false</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.transform.escape.input</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.merge.percent</name>
<value>0.66</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.job.finish-when-all-reducers-done</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.name.dir.restore</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.bind-host</name>
<value>0.0.0.0</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>yarn.sharedcache.nested-level</name>
<value>3</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.webapp.filter-entity-list-by-user</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.arrow.root.allocator.limit</name>
<value>9223372036854775807</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>_hive.hdfs.session.path</name>
<value>
/tmp/hive/hive/589fe63b-b5be-46bd-b009-b9844af3bcf3
</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>hive.server2.async.exec.async.compile</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.log-aggregation.policy.class</name>
<value>
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.max-corrupt-file-blocks-returned</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.retry.interval-ms.get-last-block-length</name>
<value>4000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.repl.include.external.tables</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.webapp.cross-origin.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.read.timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.trigger.validation.interval</name>
<value>500ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.mv.files.thread</name>
<value>15</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.hash.table.inflation.factor</name>
<value>2.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.allocator.defrag.headroom</name>
<value>1Mb</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.mover.movedWinWidth</name>
<value>5400000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.ubertask.enable</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.tez.dynamic.partition.pruning.extended</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.http.authentication.signature.secret.file</name>
<value>${user.home}/hadoop-http-auth-signature-secret</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.client.fd-clean-interval-secs
</name>
<value>60</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.tez.sessions.init.threads</name>
<value>16</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.top.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
dfs.client.read.short.circuit.replica.stale.threshold.ms
</name>
<value>1800000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.compactor.check.interval</name>
<value>300</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.node-labels.fs-store.impl.class</name>
<value>
org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-xattrs-per-inode</name>
<value>32</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.compactor.max.num.delta</name>
<value>500</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ipc.client.tcpnodelay</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.node-labels.fs-store.root-dir</name>
<value>/system/yarn/node-labels</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hadoop.system.tags</name>
<value>
YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT ,SERVER,DEBUG,DEPRICATED,COMMON,OPTIONAL
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.vectorized.reuse.scratch.columns</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.vectorized.execution.filesink.arrow.native.enabled
</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.image.compression.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.acl.reservation-enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.stale.datanode.minimum.interval</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.direct.sql.batch.size</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.principal</name>
<value>jhs/_HOST@REALM.TLD</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.compute.query.using.stats</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.querylog.enable.plan.progress</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.txn.strict.locking.mode</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.llap.plugin.acl</name>
<value>*</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.merge.mapfiles</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.adl.impl</name>
<value>org.apache.hadoop.fs.adl.AdlFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.stats.fetch.partition.stats</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.ha.zkfc.nn.http.timeout.ms</name>
<value>20000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.use.datanode.hostname</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.security.command.whitelist</name>
<value>set,reset,dfs,add,list,delete,reload,compile,llap</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.fast.upload.active.blocks</name>
<value>10</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.webapp.https.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8190
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
hive.txn.manager.dump.lock.state.on.acquire.timeout
</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>metastore.create.as.acid</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>tfile.fs.input.buffer.size</name>
<value>262144</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.storage.policy.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.ssl.keystores.factory.class</name>
<value>
org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.admin-env</name>
<value>MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.exec.orc.split.strategy</name>
<value>HYBRID</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.am.max-attempts</name>
<value>2</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.txn.timeout</name>
<value>300</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.job.emit-timeline-data</name>
<value>true</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.cleaner.enable</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.balancer.keytab.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.scratch.dir.permission</name>
<value>700</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.edekcacheloader.initial.delay.ms</name>
<value>3000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log.deletion-threads-count</name>
<value>4</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
ha.failover-controller.graceful-fence.rpc-timeout.ms
</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.auto.convert.join.shuffle.max.size</name>
<value>10000000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.balance.bandwidthPerSec</name>
<value>6250000</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.http-cross-origin.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.spark.job.max.tasks</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>orc.force.positional.evolution</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>io.mapfile.bloom.error.rate</name>
<value>0.005</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.client.libjars.wildcard</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.http.response.header.size</name>
<value>6144</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.client.block.write.replace-datanode-on-failure.enable
</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.mmap.cache.timeout.ms</name>
<value>3600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.s3guard.ddb.table.create</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.merge.rcfile.block.level</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.blocks.per.postponedblocks.rescan</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.client.thread-count</name>
<value>25</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.http.authentication.kerberos.principal</name>
<value>HTTP/_HOST@LOCALHOST</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.client-server.address</name>
<value>0.0.0.0:8045</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.webui.max.threads</name>
<value>50</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.app.mapreduce.am.command-opts</name>
<value>-Xmx4096m -Dhdp.version=${hdp.version}</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.zookeeper.clean.extra.nodes</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.stats.collect.tablekeys</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.federation.registry.base-dir</name>
<value>yarnfederation/</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.event.message.factory</name>
<value>
org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.checkpoint.max-retries</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>javax.jdo.option.ConnectionUserName</name>
<value>hive</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.path.based.cache.retry.interval.ms</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.druid.working.directory</name>
<value>/tmp/druid-indexing</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.query.result.fileformat</name>
<value>SequenceFile</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.monitor.capacity.preemption.natural_termination_factor
</name>
<value>1</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.stats.collect.scancols</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.spark.stage.max.tasks</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.image.transfer-bootstrap-standby.bandwidthPerSec
</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.block.replicator.classname</name>
<value>
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault
</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.registry.system.acls</name>
<value>sasl:yarn@, sasl:mapred@, sasl:hdfs@</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices
</name>
<value>0,1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile.reduce.params</name>
<value>${mapreduce.task.profile.params}</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
mapreduce.input.fileinputformat.split.minsize.per.node
</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.permissions.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hadoop.shell.safely.delete.limit.num.files</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.allow.user.substitution</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.materializedview.rebuild.incremental.factor</name>
<value>0.1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.balancer.getBlocks.size</name>
<value>2147483648</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ha.health-monitor.check-interval.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.compactor.delta.pct.threshold</name>
<value>0.1f</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.server2.thrift.http.cookie.auth.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.xmx.headroom</name>
<value>5%</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.max.dynamic.partitions.pernode</name>
<value>2000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.placement-constraints.handler</name>
<value>scheduler</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.is.minicluster</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.recovery.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.audit.loggers</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.health-checker.interval-ms</name>
<value>135000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.acls.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.stats.ndv.error</name>
<value>20.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.acl-modify-job</name>
<value> </value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.work-preserving-recovery.enabled
</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled
</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.service.metrics.hadoop2.frequency</name>
<value>30s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.cm.retain</name>
<value>24h</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.kerberos.min.seconds.before.relogin</name>
<value>60</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.handler-thread-count</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.writeset.reaper.interval</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.skewjoin</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.http.cross-origin.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.merge.size.per.task</name>
<value>256000000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.merge.nway.joins</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
mapreduce.jobhistory.webapp.xfs-filter.xframe-options
</name>
<value>SAMEORIGIN</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.tez.task.scale.memory.reserve.fraction</name>
<value>-1.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.scan-interval-seconds
</name>
<value>60</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.scheduler.configuration.leveldb-store.compaction-interval-secs
</name>
<value>86400</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.auto.convert.join.use.nonstaged</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.localize.resource.wait.interval</name>
<value>5000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.proxyuser.hive.hosts</name>
<value>ip-10-0-11-101.ap-northeast-1.compute.internal</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.optimize.distinct.rewrite</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.client.connect.retry.limit</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.max.open.txns</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.aux-services.spark_shuffle.class</name>
<value>org.apache.spark.network.yarn.YarnShuffleService</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.suites</name>
<value>AES/CTR/NoPadding</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>mapreduce.shuffle.transfer.buffer.size</name>
<value>131072</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.server2.materializedviews.registry.impl</name>
<value>DEFAULT</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.log-container-debug-info.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.zk.retry-interval-ms</name>
<value>1000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.list.encryption.zones.num.responses</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.hosts.provider.classname</name>
<value>
org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager
</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.druid.overlord.address.default</name>
<value>localhost:8090</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.job.committer.cancel-timeout</name>
<value>60000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.registry.dns.bind-address</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.hostname</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.clear.dangling.scratchdir</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.cache.limit.max-single-resource-mb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.rework.mapredwork</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.logger</name>
<value>query-routing</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.optimize.sampling.orderby</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.log-aggregation.retain-check-interval-seconds</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.merge.orcfile.stripe.level</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.har.impl.disable.cache</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.notification.event.poll.interval</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.wm.default.pool.size</name>
<value>4</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.stats.max.variable.length</name>
<value>100</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.scheduler.include-port-in-node-name</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.http-authentication.simple.anonymous.allowed
</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.pipeline.ecn</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.opportunistic-containers-max-queue-length
</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.encrypted-intermediate-data</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.search.filter.group
</name>
<value>(objectClass=group)</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.checksum.type</name>
<value>CRC32C</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.log-aggregation.file-controller.TFile.class</name>
<value>
org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.max.block.acquire.failures</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.script.trust</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.reformat.disabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.leveldb-state-store.compaction-interval-secs
</name>
<value>3600</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.runtime.linux.sandbox-mode</name>
<value>disabled</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.http.client.retry.policy.spec</name>
<value>10000,6,60000,10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.balancer.dispatcherThreads</name>
<value>200</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.resource.cpu-vcores</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.cluster.delegation.token.store.class</name>
<value>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.vectorized.execution.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.balancer.max-iteration-time</name>
<value>1200000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
</name>
<value>30000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.scratchdir.lock</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.vmem-pmem-ratio</name>
<value>2.1</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.webapp.xfs-filter.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.cache.target-size-mb</name>
<value>10240</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.qjournal.http.read.timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.log.server.web-service.url</name>
<value>
http://ip-10-0-11-101.ap-northeast-1.compute.internal:8188/ws/v1/applicationhistory
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.cbo.enable</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.optimize.reducededuplication</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.zk.num-retries</name>
<value>1000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.monitor.enable</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.default.rcfile.serde</name>
<value>
org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.client.password</name>
<value>anonymous</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.joinreducededuplication</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.client.write.byte-array-manager.count-reset-time-period-ms
</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.azure.saskey.usecontainersaskeyforallaccess</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.auto.convert.join</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.client.domain.socket.data.traffic</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.cbo.costmodel.network</name>
<value>150.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.reader.webapp.https.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8199
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>adl.feature.ownerandgroup.enableupn</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.vectorized.row.identifier.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>httpfs.buffer.size</name>
<value>4096</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exim.strict.repl.tables</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.zk-state-store.parent-path</name>
<value>/rmstore</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.datanode.block-pinning.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed
</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.wasbs.impl</name>
<value>org.apache.hadoop.fs.azure.Wasbs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
hive.llap.task.scheduler.node.disable.backoff.factor
</name>
<value>1.5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.storageinfo.defragment.interval.ms</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.failure.retries</name>
<value>24</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.map.speculative</name>
<value>false</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.mover.max-no-move-interval</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.aggregate.stats.cache.ttl</name>
<value>600s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.fetch.retry.interval-ms</name>
<value>1000</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.delegation.key.update-interval
</name>
<value>86400000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.cbo.show.warnings</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.azure.local.sas.key.mode</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.webui.spnego.principal</name>
<value>HTTP/_HOST@EXAMPLE.COM</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>io.erasurecode.codec.xor.rawcoders</name>
<value>xor_native,xor_java</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.repl.replica.functions.root.dir</name>
<value>/user/hive/repl/functions/</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.cachereport.intervalMsec</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.kerberos.keytab.file</name>
<value>/etc/security/keytabs/hive.service.keytab</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>ipc.maximum.data.length</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
ha.failover-controller.active-standby-elector.zk.op.retries
</name>
<value>120</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.metastore.batch.retrieve.table.partition.max</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
mapreduce.jobhistory.intermediate-user-done-dir.permissions
</name>
<value>770</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>2592000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.thrift.http.cookie.is.httponly</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
mapreduce.job.encrypted-intermediate-data.buffer.kb
</name>
<value>128</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.metastore.client.socket.timeout</name>
<value>1800s</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.webapp.address</name>
<value>${yarn.nodemanager.hostname}:8042</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.service.metrics.codahale.reporter.classes</name>
<value>
org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter,org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter,org.apache.hadoop.hive.common.metrics.metrics2.Metrics2Reporter
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.stats.correlated.multi.key.joins</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.store.class</name>
<value>
org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.tez.llap.min.reducer.per.executor</name>
<value>0.95</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.block.misreplication.processing.limit</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.client.fd-flush-interval-secs
</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.task.scheduler.timeout.seconds</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.local-dirs</name>
<value>/hadoop/yarn/local,/mnt/datavol/hadoop/yarn/local</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.list.openfiles.num.responses</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.bind-host</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>nfs.mountd.port</name>
<value>4242</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hive.vectorized.ptf.max.memory.buffering.batch.count
</name>
<value>25</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.warehouse.external.dir</name>
<value>/warehouse/tablespace/external/hive</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.resultset.use.unique.column.names</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.webui.host</name>
<value>0.0.0.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.disk.balancer.plan.threshold.percent</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.credential.clear-text-fallback</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.retry.interval.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.security.uid.cache.secs</name>
<value>14400</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.webui.max.historic.queries</name>
<value>25</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.cbo.costmodel.cpu</name>
<value>0.000001</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.aux-services.spark2_shuffle.classpath
</name>
<value>/usr/hdp/3.0.1.0-187/spark2/aux/*</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.blobstore.optimizations.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.browser-useragents-regex</name>
<value>^Mozilla.*,^Opera.*</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.client.application-client-protocol.poll-timeout-ms
</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.router.rmadmin.interceptor-class.pipeline</name>
<value>
org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.amrmproxy.interceptor-class.pipeline
</name>
<value>
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.variable.substitute.depth</name>
<value>40</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.netty.low.watermark</name>
<value>32768</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.resource.check.interval</name>
<value>5000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.fsdatasetcache.max.threads.per.volume</name>
<value>4</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.zk.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:2181,ip-10-0-11-120.ap-northeast-1.compute.internal:2181,ip-10-0-11-12.ap-northeast-1.compute.internal:2181
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>javax.jdo.PersistenceManagerFactoryClass</name>
<value>
org.datanucleus.api.jdo.JDOPersistenceManagerFactory
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.fetch.output.serde</name>
<value>org.apache.hadoop.hive.serde2.DelimitedJSONSerDe</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.conversion.rule</name>
<value>none</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-container-queuing.max-queue-length
</name>
<value>15</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.hashtable.loadfactor</name>
<value>0.75</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.auto.convert.join.noconditionaltask.size</name>
<value>858783744</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.optimize.partition.columns.separate</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.outliers.report.interval</name>
<value>30m</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.delegation-token-renewer.thread-count
</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.service.framework.path</name>
<value>/hdp/apps/${hdp.version}/yarn/service-dep.tar.gz</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.viewfs.rename.strategy</name>
<value>SAME_MOUNTPOINT</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.cli.tez.session.async</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.qjournal.prepare-recovery.timeout.ms</name>
<value>120000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class
</name>
<value>
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.local.time.zone</name>
<value>LOCAL</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.allocator.arena.count</name>
<value>8</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.server2.thrift.exponential.backoff.slot.length
</name>
<value>100ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.compress.intermediate</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.exec.check.crossproducts</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.cache.defaultfs.only.native.fileid</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.listbucketing</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.limit.connections.per.user</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.task.exit.timeout.check-interval-ms</name>
<value>20000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.qjournal.http.open.timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.connection.timeout.ms
</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.connect.timeout</name>
<value>180000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.am.max-attempts</name>
<value>2</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.datanode.http.address</name>
<value>0.0.0.0:50075</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.stats.map.num.entries</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.authorization</name>
<value>false</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.order.columnalignment</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.task.merge.progress.records</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.optimize.sampling.orderby.percent</name>
<value>0.1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.qjournal.new-epoch.timeout.ms</name>
<value>120000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.server2.limit.connections.per.ipaddress</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.event.clean.freq</name>
<value>0s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.image.transfer.timeout</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.ftp.transfer.mode</name>
<value>BLOCK_TRANSFER_MODE</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
hive.vectorized.adaptor.suppress.evaluate.exceptions
</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.orc.gap.cache</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.ifile.readahead</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.metastore.fshandler.threads</name>
<value>15</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.task.skip.start.attempts</name>
<value>2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.committer.threads</name>
<value>8</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.uploader.server.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.llap.io.lrfu.lambda</name>
<value>1.0E-6</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.timeline-service.http-authentication.proxyuser.root.groups
</name>
<value>*</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.s3a.experimental.input.fadvise</name>
<value>normal</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
</name>
<value>10000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.wm.allow.any.pool.via.jdbc</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.io.rcfile.column.number.conf</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.materializedview.rebuild.incremental</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.limit.optimize.fetch.max</name>
<value>50000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.ha.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>mapreduce.job.cache.limit.max-resources-mb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.exec.copyfile.maxsize</name>
<value>33554432</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.limit.connections.per.user.ipaddress</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction
</name>
<value>0.6</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.input.fileinputformat.split.minsize</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.txn.max.open.batch</name>
<value>1000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.ha.tail-edits.rolledits.timeout</name>
<value>60</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.schema.info.class</name>
<value>
org.apache.hadoop.hive.metastore.MetaStoreSchemaInfo
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.ttl-enable</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.node-labels.provider.fetch-interval-ms
</name>
<value>1800000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.bin.path</name>
<value>/usr/hdp/current/hadoop-client/bin/hadoop</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.top.windows.minutes</name>
<value>1,5,25</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.io.encode.formats</name>
<value>org.apache.hadoop.mapred.TextInputFormat,</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.lock.query.string.max.length</name>
<value>1000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.backup.http-address</name>
<value>0.0.0.0:50105</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.query.reexecution.max.count</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.container.stderr.tail.bytes</name>
<value>4096</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.auto.convert.sortmerge.join</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.namenode.delegation.token.max-lifetime</name>
<value>604800000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.maxattempts</name>
<value>4</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.llap.plugin.rpc.num.handlers</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.lazywriter.interval.sec</name>
<value>60</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>datanucleus.cache.level2</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.groupby.skewindata</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.compactor.cleaner.run.interval</name>
<value>5000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.image.transfer.bandwidthPerSec</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.copyfile.maxnumfiles</name>
<value>1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.max.extra.edits.segments.retained</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.nm.uploader.replication.factor</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.federation.subcluster-resolver.class</name>
<value>
org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.fileformat.check</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.mmap.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.job.ubertask.maxmaps</name>
<value>9</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.txn.xlock.iow</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.in.place.progress</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.client.resolve.remote.symlinks</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
dfs.client.block.write.replace-datanode-on-failure.policy
</name>
<value>DEFAULT</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.tez.smb.number.waves</name>
<value>0.5</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.shuffle.log.separate</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.orc.splits.directory.batch.ms</name>
<value>0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hive.query.reexecution.always.collect.operator.stats
</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.transport.mode</name>
<value>binary</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.server2.webui.cors.allowed.headers</name>
<value>
X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by
</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.ssl</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.aux.jars.path</name>
<value>
file:///usr/hdp/current/hive-server2/lib/hive-hcatalog-core.jar
</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>yarn.system-metricspublisher.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>datanucleus.schema.validateConstraints</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.webui.cors.allowed.methods</name>
<value>GET,POST,DELETE,HEAD</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.journalnode.enable.sync</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.task.files.preserve.failedtasks</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.paging.maximum</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.qjournal.finalize-segment.timeout.ms</name>
<value>120000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.optimize.cte.materialize.threshold</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.max-num-blocks-to-log</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.reduce.shuffle.consumer.plugin.class</name>
<value>org.apache.hadoop.mapreduce.task.reduce.Shuffle</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.cluster.max-application-priority</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.spark.client.secret.bits</name>
<value>256</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.indexer.segments.granularity</name>
<value>DAY</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.journalnode.http-address</name>
<value>0.0.0.0:8480</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.support.special.characters.tablename</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage
</name>
<value>90.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.retry.throttle.interval</name>
<value>1000ms</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.hbase.snapshot.restoredir</name>
<value>/tmp</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.http.port</name>
<value>10501</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.mover.address</name>
<value>0.0.0.0:0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.scheduler.configuration.store.max-logs</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.keytab</name>
<value>/etc/krb5.keytab</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.user.home.dir.prefix</name>
<value>/user</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.http.staticuser.user</name>
<value>dr.who</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.ha.automatic-failover.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.cached-dfsused.check.interval.ms</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>datanucleus.identifierFactory</name>
<value>datanucleus1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.http.policy</name>
<value>HTTP_ONLY</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.blockreport.intervalMsec</name>
<value>21600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.tez.dag.status.check.interval</name>
<value>500ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.hashtable.initialCapacity</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.lifeline.handler.ratio</name>
<value>0.10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
hive.llap.external.splits.order.by.force.single.split
</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>io.seqfile.compress.blocksize</name>
<value>1000000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.mapjoin.hybridgrace.hashtable</name>
<value>false</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.llap.daemon.delegation.token.lifetime</name>
<value>14d</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.admin.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8141
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
dfs.namenode.list.reencryption.status.num.responses
</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.registry.rm.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ha.zookeeper.session-timeout.ms</name>
<value>10000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.llap.auto.enforce.tree</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.checksum.algo.impl</name>
<value>
org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.replication.max</name>
<value>50</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-manager.thread-count</name>
<value>20</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.groupby.limit.extrastep</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.groups.negative-cache.secs</name>
<value>30</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.impl</name>
<value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.retry.times</name>
<value>5</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.privilege.synchronizer.interval</name>
<value>1800s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.merge.tezfiles</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.metastore.event.expiry.duration</name>
<value>0s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>file.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.async.log.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hiveserver2-site.xml</source>
</property>
<property>
<name>hive.arrow.batch.size</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.repl.add.raw.reserved.namespace</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.group.mapping</name>
<value>
org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.store.fs.uri</name>
<value>${hadoop.tmp.dir}/mapred/history/recoverystore</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.default.chunk.view.size</name>
<value>32768</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.strict.checks.type.safety</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.monitor.policies</name>
<value>
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.cbo.returnpath.hiveop</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.keytab</name>
<value>/etc/krb5.keytab</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.optimize.ppd</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.zookeeper.namespace</name>
<value>hive_zookeeper_namespace</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.transactional.table.scan</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.task.scheduler.wait.queue.size</name>
<value>10</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>datanucleus.schema.autoCreateAll</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>hive.llap.am.use.fqdn</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.spark.dynamic.partition.pruning.map.join.only</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.reduce.input.buffer.percent</name>
<value>0.0</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.app-cache-size
</name>
<value>10</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
dfs.datanode.ec.reconstruction.stripedread.buffer.size
</name>
<value>65536</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:10020
</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.namenode.num.checkpoints.retained</name>
<value>2</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.optimize.update.table.properties.from.serde</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.wm.pool.metrics</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.max.split.locations</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.tez.enable.memory.manager</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.reduce.log.level</name>
<value>INFO</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>yarn.timeline-service.webapp.address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:8188
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.autogen.columnalias.prefix.includefuncname</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.resource.memory.enforced</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.repl.bootstrap.dump.open.txn.timeout</name>
<value>1h</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.mapjoin.hybridgrace.minwbsize</name>
<value>524288</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.optimize.null.scan</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
hadoop.security.groups.cache.background.reload.threads
</name>
<value>3</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.workaround.non.threadsafe.getpwuid</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
dfs.client.read.shortcircuit.streams.cache.expiry.ms
</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.query.reexecution.strategies</name>
<value>overlay,reoptimize</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.direct.sql.max.query.length</name>
<value>100</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.security.dns.log-slow-lookups.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.rm.system-metricspublisher.emit-container-events
</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
hadoop.security.crypto.codec.classes.aes.ctr.nopadding
</name>
<value>
org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.default.serde</name>
<value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.querylog.plan.progress.interval</name>
<value>60000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.timeline-service.reader.class</name>
<value>
org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.resultset.max.fetch.size</name>
<value>10000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.druid.maxTries</name>
<value>5</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.auto.progress.timeout</name>
<value>0s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.job.end-notification.retry.interval</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.llap.auto.enforce.vectorized</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.socket.connect-timeout</name>
<value>60s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.retain-seconds
</name>
<value>604800</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.remote-app-log-dir</name>
<value>/app-logs</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.log.level</name>
<value>INFO</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.allowed-headers</name>
<value>
X-Requested-With,Content-Type,Accept,Origin,WWW-Authenticate,Accept-Encoding,Transfer-Encoding
</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>hive.input.format</name>
<value>
org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server.read.socket.timeout</name>
<value>10s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms
</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.wm.worker.threads</name>
<value>4</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.group.mapping.ldap.directory.search.timeout
</name>
<value>10000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.allowed-methods</name>
<value>GET,PUT,POST,OPTIONS,HEAD,DELETE</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.namenode.decommission.interval</name>
<value>30s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.typecheck.on.insert</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
</name>
<value>86400</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.compactor.history.retention.failed</name>
<value>3</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.llap.daemon.yarn.container.mb</name>
<value>18432</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.insert.into.external.tables</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.retry.max.attempts</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.delete.debug-delay-sec</name>
<value>0</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.namenode.https-address</name>
<value>
ip-10-0-11-101.ap-northeast-1.compute.internal:50470
</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
yarn.scheduler.capacity.ordering-policy.priority-utilization.underutilized-preemption.enabled
</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.s3a.s3guard.cli.prune.age</name>
<value>86400000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.provided.aliasmap.inmemory.dnrpc-address</name>
<value>0.0.0.0:50200</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.skip.proc-count.auto-incr</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.methods-to-ignore</name>
<value>GET,OPTIONS,HEAD,TRACE</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.service.metrics.file.frequency</name>
<value>5000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metastore.db.type</name>
<value>MYSQL</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>mapreduce.jobtracker.webinterface.trusted</name>
<value>false</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>fs.azure.authorization</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.active.passive.ha.registry.namespace</name>
<value>hs2ActivePassiveHA</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.max-age</name>
<value>1800</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>dfs.https.server.keystore.resource</name>
<value>ssl-server.xml</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-aggregation.compression-type</name>
<value>gz</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.hosts.exclude</name>
<value>/etc/hadoop/conf/dfs.exclude</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>
yarn.scheduler.configuration.mutation.acl-policy.class
</name>
<value>
org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy
</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.auto.convert.sortmerge.join.to.mapjoin</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>ipc.client.connect.timeout</name>
<value>20000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.insert.into.multilevel.dirs</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>datanucleus.transactionIsolation</name>
<value>read-committed</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.metadata.move.exported.metadata.to.trash</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
dfs.namenode.path.based.cache.block.map.allocation.percent
</name>
<value>0.25</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.cross-origin.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>fs.wasbs.impl</name>
<value>
org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure
</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.vectorized.use.checked.expressions</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.https.port</name>
<value>50470</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>mapreduce.output.fileoutputformat.compress</name>
<value>false</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.max-lock-hold-to-release-lease-ms</name>
<value>25</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.client.failover-retries-on-socket-timeouts</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.client.socket.lifetime</name>
<value>0s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.buffer.dir</name>
<value>/mnt/datavlo/tmp/hadoop-ec2-user/s3a</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>
dfs.client.block.write.replace-datanode-on-failure.best-effort
</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.fetch.task.aggr</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.aux-services.spark2_shuffle.class</name>
<value>org.apache.spark.network.yarn.YarnShuffleService</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.optimize.reducededuplication.min.reducer</name>
<value>4</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.tez.dynamic.partition.pruning.max.event.size</name>
<value>1048576</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.zk-delegation-token-node.split-index
</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.metastore.port</name>
<value>9083</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.memory.mode</name>
<value>cache</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.http.authentication.kerberos.keytab</name>
<value>${user.home}/hadoop.keytab</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.testing.short.logs</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.retry.limit</name>
<value>${fs.s3a.attempts.maximum}</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.server2.metrics.enabled</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hiveserver2-site.xml</source>
</property>
<property>
<name>hive.tez.dynamic.semijoin.reduction.for.dpp.factor</name>
<value>1.0</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ipc.ping.interval</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.monitor.capacity.preemption.monitoring_interval
</name>
<value>15000</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
hive.optimize.update.table.properties.from.serde.list
</name>
<value>org.apache.hadoop.hive.serde2.avro.AvroSerDe</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.nm.uploader.thread-count</name>
<value>20</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.compactor.history.retention.succeeded</name>
<value>3</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.thrift.http.max.idle.time</name>
<value>1800s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.test.mode</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.storageinfo.defragment.ratio</name>
<value>0.75</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.auto.convert.sortmerge.join.reduce.side</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.admin.address</name>
<value>0.0.0.0:10033</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.pmem-check-enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.user.install.directory</name>
<value>/user/</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.webapp.rest-csrf.custom-header
</name>
<value>X-XSRF-Header</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.query.reexecution.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.test.vectorizer.suppress.fatal.exceptions</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.exec.max.dynamic.partitions</name>
<value>5000</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.bin.path</name>
<value>/usr/hdp/current/hadoop-client/bin/yarn</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.upgrade.domain.factor</name>
<value>${dfs.replication}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.repl.rootdir</name>
<value>/user/hive/repl/</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.kms.client.failover.sleep.max.millis
</name>
<value>2000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.java.opts</name>
<value>-Xmx8192m</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>fs.s3a.fast.upload</name>
<value>true</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.entity-group-fs-store.active-dir
</name>
<value>/ats/active/</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
</name>
<value>10737418240</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.direct.sql.max.elements.values.clause</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.ppd.remove.duplicatefilters</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.sharedcache.admin.address</name>
<value>0.0.0.0:8047</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.loadedjob.tasks.max</name>
<value>-1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.session.id</name>
<value>589fe63b-b5be-46bd-b009-b9844af3bcf3</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>dfs.client.cached.conn.retry</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.optimize.union.remove</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.test.authz.sstd.hs2.mode</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.orc.cache.stripe.details.mem.size</name>
<value>256Mb</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>fs.s3a.readahead.range</name>
<value>64K</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed
</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ipc.client.low-latency</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>javax.jdo.option.ConnectionPassword</name>
<value/>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>yarn.nodemanager.container-metrics.enable</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
dfs.client.block.write.locateFollowingBlock.retries
</name>
<value>5</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.du.reserved</name>
<value>116869166592</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.llap.mapjoin.memory.oversubscribe.factor</name>
<value>0.3f</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hadoop.registry.zk.retry.ceiling.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.address</name>
<value>0.0.0.0:50010</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.spark.rsc.conf.list</name>
<value>
hive.spark.optimize.shuffle.serde,hive.spark.client.future.timeout
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.lock.numretries</name>
<value>100</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.spark.client.server.connect.timeout</name>
<value>90000ms</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.resourcemanager.delegation.token.renew-interval
</name>
<value>86400000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.num.extra.edits.retained</name>
<value>1000000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.security.authorization.task.factory</name>
<value>
org.apache.hadoop.hive.ql.parse.authorization.HiveAuthorizationTaskFactoryImpl
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.admin.acl</name>
<value>*</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.datanode.drop.cache.behind.reads</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.balance.max.concurrent.moves</name>
<value>50</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.abfs.impl</name>
<value>org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ipc.client.ping</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.error.on.empty.partition</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.mapper.cannot.span.multiple.partitions</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.numa-awareness.read-topology</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.directoryscan.interval</name>
<value>21600s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.cbo.cnf.maxnodes</name>
<value>-1</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.socket-timeout</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.exec.reducers.max</name>
<value>1009</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
dfs.namenode.snapshotdiff.allow.snap-root-descendant
</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.input.fileinputformat.split.maxsize</name>
<value>256000000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.client.consistent.splits</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
mapreduce.job.local-fs.single-disk-limit.check.interval-ms
</name>
<value>5000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.metastore.archive.intermediate.extracted</name>
<value>_INTERMEDIATE_EXTRACTED</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.script.operator.id.env.var</name>
<value>HIVE_SCRIPT_OPERATOR_ID</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.webhdfs.netty.high.watermark</name>
<value>65535</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.disk-health-checker.enable</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>
yarn.resourcemanager.ha.automatic-failover.zk-base-path
</name>
<value>/yarn-leader-election</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.tez.hs2.user.access</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.materializedview.rewriting.time.window</name>
<value>0min</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.retrycache.expirytime.millis</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.spark.client.rpc.max.size</name>
<value>52428800</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.webapp.rest-csrf.methods-to-ignore
</name>
<value>GET,OPTIONS,HEAD</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.connection.maximum</name>
<value>15</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.limit.optimize.enable</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.session.silent</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.jobhistory.webapp.https.address</name>
<value>0.0.0.0:19890</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.llap.cache.allow.synthetic.fileid</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>ipc.server.tcpnodelay</name>
<value>true</value>
<final>false</final>
<source>core-site.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.client.job.max-retries</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>seq.io.sort.factor</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.metastore.expression.proxy</name>
<value>
org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.daemon.output.service.max.pending.writes</name>
<value>8</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.webui.enable.cors</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
yarn.timeline-service.client.internal-timers-ttl-secs
</name>
<value>420</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.zk.acl</name>
<value>world:anyone:rwcda</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>yarn.minicluster.control-resource-monitoring</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.orc.cache.use.soft.references</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.spark.optimize.shuffle.serde</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.transferTo.allowed</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.tez.log.level</name>
<value>INFO</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.stats.dbclass</name>
<value>fs</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.druid.select.distribute</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>yarn.nodemanager.webapp.rest-csrf.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hive.server2.thrift.worker.keepalive.time</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.ec.system.default.policy</name>
<value>RS-6-3-1024k</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
mapreduce.job.speculative.speculative-cap-running-tasks
</name>
<value>0.1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.hdfs-servers</name>
<value>${fs.defaultFS}</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.multipart.purge.age</name>
<value>86400</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.use.legacy.blockreader.local</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.hedged.read.threadpool.size</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.sync.behind.writes</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.stats.estimate</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.failover.sleep.base.millis</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.wasb.impl</name>
<value>org.apache.hadoop.fs.azure.Wasb</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.fetch.retry.timeout-ms</name>
<value>30000</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>hive.autogen.columnalias.prefix.label</name>
<value>_c</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.datanode.data.dir.perm</name>
<value>750</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hive.mapjoin.optimized.hashtable</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>dfs.checksum.combine.mode</name>
<value>MD5MD5CRC</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.lock.sleep.between.retries</name>
<value>60s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.fileoutputcommitter.algorithm.version</name>
<value>2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.exec.submit.local.task.via.child</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
hive.metastore.client.drop.partitions.using.expressions
</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.client.datanode-restart.timeout</name>
<value>30s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.metastore.aggregate.stats.cache.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.hdfs.configuration.version</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.minicluster.fixed.ports</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.replication.max-streams</name>
<value>2</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>
yarn.nodemanager.container-retry-minimum-interval-ms
</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.reencrypt.edek.threads</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.restart.replica.expiration</name>
<value>50</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ipc.server.listen.queue.size</name>
<value>128</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.ssl.file.buffer.size</name>
<value>65536</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.multipart.purge</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.list.version</name>
<value>2</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.prewarm.numcontainers</name>
<value>3</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.server2.zookeeper.publish.configs</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
yarn.nodemanager.runtime.linux.docker.default-container-network
</name>
<value>host</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.llap.io.encode.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.explain.dependency.append.tasktype</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.server2.async.exec.shutdown.timeout</name>
<value>10s</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hadoop.registry.dns.zone-subnet</name>
<value>172.17.0.0</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.provided.aliasmap.inmemory.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.dispatcher.drain-events.timeout</name>
<value>300000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.ec.reconstruction.xmits.weight</name>
<value>0.5</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.webapp.ui2.enable</name>
<value>true</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.llap.mapjoin.memory.monitor.check.interval</name>
<value>100000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.runtime.linux.docker.capabilities</name>
<value>
CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP, SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE
</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>hive.server2.idle.operation.timeout</name>
<value>6h</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.test.fail.heartbeater</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.io.encode.alloc.size</name>
<value>256Kb</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB
</name>
<value>org.apache.hadoop.ipc.ProtobufRpcEngine</value>
<final>false</final>
<source>programmatically</source>
</property>
<property>
<name>hive.optimize.sampling.orderby.number</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-directory-items</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.llap.allow.permanent.fns</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>yarn.nodemanager.log.retain-seconds</name>
<value>604800</value>
<final>false</final>
<source>yarn-site.xml</source>
</property>
<property>
<name>dfs.image.transfer.chunksize</name>
<value>65536</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.optimize.bucketmapjoin.sortedmerge</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>
dfs.client.block.write.replace-datanode-on-failure.min-replication
</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.direct.sql.max.elements.in.clause</name>
<value>1000</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.llap.remote.token.requires.signing</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.data.transfer.client.tcpnodelay</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hive.map.aggr</name>
<value>true</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.fetch.task.conversion.threshold</name>
<value>1073741824</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>fs.du.interval</name>
<value>600000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.vectorized.execution.ptf.enabled</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>mapreduce.reduce.markreset.buffer.percent</name>
<value>0.0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.connection-keep-alive.timeout</name>
<value>5</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hive.tez.task.scale.memory.reserve.fraction.max</name>
<value>0.5</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>
hadoop.security.kms.client.encrypted.key.cache.size
</name>
<value>500</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hive.txn.manager</name>
<value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
<final>false</final>
<source>file:/etc/hive_llap/conf/hive-site.xml</source>
</property>
<property>
<name>hive.server2.map.fair.scheduler.queue</name>
<value>true</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>hive.allow.udf.load.on.demand</name>
<value>false</value>
<final>false</final>
<source>programmatically</source>
<source>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2bd2b28e
</source>
</property>
<property>
<name>dfs.cluster.administrators</name>
<value> hdfs</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hadoop.registry.zk.root</name>
<value>/registry</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.client.job.retry-interval</name>
<value>2000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
</configuration>
